\chapter{Itroduction} \label{chap:intro}

\section{Background} \label{sec:back}
Charged particle accelerators have been productive experimental tools for fundamental physics experiments, from rutherfords use of natural acceleration of alpha particles for the discovery of the nucleus to the contemperary multinational physics collaborations centered at the Large Hadron Collider. "Maybe add other physics discoveries" In addition to their useful nature as tools, particle accelerators provide an interesting system to study dynamics in a controlled environment. These same dynamical studies then have direct impacts on the construction of new machines for fundamental studies. As the experiments drive increasing energy and power demands on the beams, careful control of losses becomes more important.

To tackle the challenge of controlling energetic subatomic particles we first have to choose our tools. Some of the earliest "accelerator" experiments relied on energetic decay products, leveraging the weak nuclear force. This approach is quickly limited by the characteristic energies of these decays. Gravity can be easily dismissed as too weak and effectively fixed on the earth's surface. Bulk material interactions can be used to affect the path of particles, but they cannot accelerate and tend to cause significant losses. The default choice has been electromagnetic fields, dating back to early cathode ray experiments. These fields are easy to produce and control and can both steer and provide energy to charged particles. Naturally this restricts our ability to work with neutral particle beams, but this can be typically overcome with a charged primary beam to produce a neutral secondary beam as is the case in succesful neutron spallation and neutrino beam facilities.

Scaling the electrostatic fields from our early cathode ray tubes are a straightforward starting point for accelerating particles. A large voltage applied across carefully shaped electrodes can simultaneously accelerate and focus a beam. This was the guiding principle for early Van De Graf machines like the Westinghouse atom smashe and the Cockroft-Walton style proton sources popularly used in the mid 20th century. This approach still finds use in pellotrons and "tandem" accelerators for low energy nuclear experimentation. However, the practical limits of breakdown gradients quickly limit the energy from such devices. Using an oscillating electric field is a practical approach to bypassing this limitation in two ways. First, the gradients of oscillaitng fields may be much higher than static fields. Second, by selectively timing the particles to be accelerated, the particle can gain energy from the gradient at the frequency of the oscillation. There are a few ways this is currently accomplished. The first is simply physically shielding the particles from the negative gradient, as is done in the Alvarez or drift tube linear accelerator (linac). If the velocity of a travelling EM wave is matched to that of the desired accelerated particle the beam can always see a positive gradient and "surf" the wave. This is the approach of a travelling wave linac, typefied by the original SLAC linac. Another approach is to adjust the path legth of the beam between standing wave structures (usually called cavities) and the phase of these cavities to always arrive in a positive gradient. There are two main approaches using this technique. Either a sequence of cavities with proper phase are used sequentially, a resonant cavity linac. Or, the particles are recirculated to a cavity many times, the case with a broad variety of cyclic machines.

So far the problem of imparting energy to the particles has been given precendence, but naturally the particles must also be steered and focused for useful purposes. Here we can consider magnetic fields as well as electric. While not possible to be used for energy gain, magnetic fields are the preferred option for steering and control. While electrostatic fields are used in some low energy applications, the proportional scaling of the force with momentum from a magnetic field pay divedends as beam energy increases and is the dominant approach for accelerator applications. We can consider then the earliest cyclic machine, the cyclotron. This consists of a single resonant electric gap in a static perpendicular magnetic field. By properly scaling the field strength, in the nonrelatavistic approximation, the classical cyclotron frequency means that the particle will continue to cycle at the correct frequency to see a positive gradient and gain energy. As a result, a modest field on the gap seen many times can result in a significant energy gain for the beam. The tradeoff is that now we have a periodic system which must support stable motion in the plane transverse to the direction of acceleration. This is not unique to cyclic machines.

\section{General Beamline Hamiltonian} \label{sec:genHam}

This problem of stability is of course not unique to accelerators and has a long history of study of dynamical systems. Accordingly, we can construct a hamiltonian of the system. To evaluate the inherent stability of the system we will construct the Hamiltonan for a single particle in external confining potentials in two dimensions. Notably this does not include the self fields of the particle, or of the interactions of many particles in a beam. We are specifically interested in a Hamiltonian which describes a relativitic particle in electromagnetic fields. This results in the general Hamiltonian \ref{eq:H_em} where $\Phi$ and $\vec{A}$ are the typical scalar and vector potentials related to the Electric and Magnetic fields by \ref{eq:phi_A}

\begin{equation} \label{eq:H_em}
H_{EM} = E_{\Phi} = c\sqrt{(\vec{P} - q\vec{A}) + m^2 c^2} + q\Phi
\end{equation}

\begin{equation} \label{eq:phi_A}
\begin{split} 
\vec{E} &= -\nabla \Phi - \frac{\partial \vec{A}}{\partial t}\\
\vec{B} &= \nabla \times \vec{A}
\end{split}
\end{equation}

Here the canonical momentum $\vec{P}$ is related to the mechanical momentum by \ref{eq:P_mv}

\begin{equation} \label{eq:P_mv}
	\vec{P} = \gamma m\vec{v} - q \vec{A}
\end{equation}

And this Hamiltonian is then the total energy of the particle including the contribution from the scalar potential, I will call this $E_{\Phi}$ to differentiate it from the total energy in the absence of the scalar potential.

We will aim to find the equations of motion for the linearized condition and. We would like to refine this expression by changing to a more useful coordinate system. When studying the dynamics of a particle accelerator it is useful to investigate the motion of the particles with respect to some reference trajectory rather their absolute coordinates in the lab frame. To start with, we adopt a Frenet-Serret (Fig. \ref{fig:frenetSerret}) coordinate system where the coordinate axes are defined with respect to a tangent vector of an arbitrary curved path.  In the case of many accelerator systems, the situation is simpler than this. In practice, bending is only in a single plane, typically horizontal in the lab frame along the floor. Additionally, if bending is only generated from the motion of charged particles in a static magnetic field, the bent path will be circles of a characteristic bending radius $\rho$. The result of this transformation only ends up modifying the momentum along the curved trajectory by a factor of $1 + \frac{x}{\rho}$ and gives us the hamiltonian $H_{f.s.}$ in \ref{eq:H_fs}. This coordinate transformation does not affect the value of the Hamiltonian, so it is still equivalent to the total energy of the test particle with the scalar field contribution. Strictly speaking this is the case for transfer lines, linacs, synchrotrons and storage rings. There are other style machines, such as cyclotrons and fixed field alternating gradient accelerators which demand a different treatment of the dynamics, but are beyond the scope of this derevation.

\begin{figure} \label{fig:frenetSerret}
	\centering
	\includegraphics[width=0.5\linewidth]{placeholder.pdf}
	\caption{Illustration of Frenet-Serret style Coordinate System}
\end{figure}

\begin{equation} \label{eq:H_fs}
	H_{f.s.} = E_{\Phi} = c\sqrt{\left(\frac{p_s}{1 + x/\rho} - qA_s\right)^2 + (P_x - qA_x)^2 + (P_y- qA_y)^2+ m^2c^2} + q\Phi
\end{equation}

Since an accelerator is composed of sequential elements along this reference trajectory, it is useful to change the independent variable to the spacial coordinate along the trajectory. Inspecting the action with respect to the s dimension shows defining the new hamiltonain as $H_s(x,p_x,y,p_y,t,-E_{\Phi};s) = -p_s$ only requires rearranging Eq. \ref{eq:H_fs} to arrive at Eq. \ref{eq:H_s}.

\begin{multline} \label{eq:H_s}
	H_s = -\left(1 + \frac{x}{\rho}\right)\sqrt{\left(\frac{E_{\Phi} - q\Phi}{c}\right)^2 - (P_x -q A_x)^2 - (P_y - q A_y)^2 - m^2c^2}\\ - \left(1 + \frac{x}{\rho}\right)qA_s
\end{multline}

There is one more coordinate transformation we would like to make. Currently our longitudinal cannonical coordinate is time, which will increase quickly along the beam line and become cumbersome. We would like to define the position of the beam with respect to some reference particle, which has the ideal quantites we would like in our accelerated beam. Correspondingly we define a particle on our reference trajectory with a momentum $p_o$ (Eq.\ref{eq:p_o}) directed along the reference trajectory.

\begin{equation} \label{eq:p_o}
	p_o = \beta_o \gamma_o m c
\end{equation}

We can then scale the overall Hamiltonian by this reference momentum Eq. \ref{eq:H_p}. The equations of motion are still satisfied with the inclusion of the already substituted variable changes in Eq. \ref{eq:pOverP}.

\begin{multline} \label{eq:H_p}
	H_p = \frac{H_s}{p_o} = - \left(1 + \frac{x}{\rho}\right)\frac{q}{p_o}A_s\\
-\left(1 + \frac{x}{\rho}\right)\sqrt{\left(\frac{\tilde{E}_{\Phi} - \frac{q}{p_o}\Phi}{c}\right)^2 - \left(p_x -\frac{q}{p_o} A_x\right)^2 - \left(p_y - \frac{q}{p_o} A_y\right)^2 - \frac{m^2c^2}{p_o^2}}
\end{multline}


\begin{equation} \label{eq:pOverP}
\begin{split}
	p_x &= \frac{P_x}{p_o}\\
	p_y &= \frac{P_y}{p_o}\\
	\tilde{E_{\Phi}} &= \frac{E_{\Phi}}{p_o}
\end{split}
\end{equation}

The last coordinate transformation we will make is to shift the longitudinal position of the test particle with respect to our reference particle. Using a generating function of the form Eq. \ref{eq:relGen}


\begin{equation} \label{eq:relGen}
	G_2(x,p_x,y,p_y,t,p_t;s) = x p_x  + y p_y + \left(ct - \frac{s}{\beta_o}\right)\left(p_t - \frac{1}{\beta_o}\right)
\end{equation}

The $x,y$ coordinates are not affected by the transformation, but we have the following new longitudinal coordinates in Eq. \ref{eq:statCoords}. Here we follow the direction convention chosen in ImpactX as it will be the native coordinate system for our simulation results later on.

\begin{equation} \label{eq:statCoords}
\begin{split}
	ct &= ct - \frac{s}{\beta_o}\\
	\tilde{p_t} &= \frac{1}{\beta_o} - \frac{\tilde{E_{\Phi}}}{c}\\
	\tilde{H_p} &= H_p - \frac{\tilde{p_t}}{\beta_o} + \frac{1}{\beta_o^2}
\end{split}
\end{equation}

After substitution and removing the constant $\frac{1}{\beta_o^2}$ term we have the Hamiltonian in Eq. \ref{eq:H_A}

\begin{multline} \label{eq:H_A}
	H_A = - \left(1 + \frac{x}{\rho}\right)\frac{q}{p_o}A_s - \frac{\tilde{p_t}}{\beta_o}\\
	-\left(1 + \frac{x}{\rho}\right)\sqrt{\left(\frac{1}{\beta_o} - \tilde{p_t}  - \frac{q}{p_o c}\Phi\right)^2 - \left(p_x -\frac{q}{p_o} A_x\right)^2 - \left(p_y - \frac{q}{p_o} A_y\right)^2 - \frac{m^2c^2}{p_o^2}}
\end{multline}

We then have arrived at the general Hamiltonian for a particle along our reference trajectory with respect to a nominal reference particle in arbitrary electromagnetic fields. 

From here we now need to decide on which fields to apply to our particle for stable accelration. We are interested in representing the basic accelerator components, i.e. transverse magnets and radiofrequency cavities. For this case we can take $\Phi, A_x, A_y = 0$, which yields the Hamiltonian in \ref{eq:H_bet}. Components that do not meet these conditions, like a solenoid, can be treated analagously to the following approach, but are omitted for brevity.

\begin{equation} \label{eq:H_bet}
	H = -\left(1 + \frac{x}{\rho}\right)\sqrt{\left(\frac{1}{\beta_o} - p_t \right)^2 - p_x^2 - p_y^2- \frac{m^2c^2}{p_o^2}} - \frac{p_t}{\beta_o} - \left(1 + \frac{x}{\rho}\right)\frac{q}{p_o}A_s
\end{equation}

With the scalar potential set to zero, we arrive at a common set of canonoical coordinates used for studies of acclerator dynamics (Eq. \ref{eq:coords}). The relevant difference here from our coordinates above is that now the longitudinal momentum $p_t$ is the difference in the relativistic energy (Eq. \ref{eq:relEnergy}) of the test and reference particle. These definitons are now completely consistent with those used in ImpactX. I refer to the longitudinal spacial coordinate as $ct$ to continually remind that the units are in meters.

\begin{equation} \label{eq:coords}
\begin{split}
x &= x\\
p_x &= \frac{P_x}{p_o}\\
y &= y\\
p_y &= \frac{P_y}{p_o}\\
ct &= c(t-t_o)\\
p_t &= \frac{E_o-E}{p_o c}
\end{split}
\end{equation}

\begin{equation} \label{eq:relEnergy}
	E = \gamma m c^2 \Rightarrow E_o = \gamma_o m c^2
\end{equation}

There are two prominent alternative coordinate definitions in use. The first is an alternative longitudinal coordinate parameterization using the difference in momentum instead of energy, usually called $\delta$, which also changes the longitudinal coordinate defintion to spacial offset. The relationship between these coordinates and the coordinates in Eq. \ref{eq:coords} is given in Eq. \ref{eq:delCoord} and expanded upon in Appendix \ref{apx:delToPt}.

\begin{equation} \label{eq:delCoord}
\begin{split}
	\delta &= \frac{p-p_o}{p_o} = \sqrt{p_t^2 -\frac{2}{\beta_o}p_t + 1} -1 \approx -\frac{p_t}{\beta_o}\\
	z &= ct\frac{\sqrt{\beta_o^2 + \beta_o^2 p_t^2 - 2\beta_o p_t}}{\beta_o p_t - 1} \approx  - \beta_o c t
\end{split}
\end{equation}

The other coordinate convention wich deserves mention is the use of $x' = \frac{dx}{ds}$. This is an easy to understand coordinate, but it is in general non-cannonical and so is avoided in our Hamiltonain based approach. This value converges with our definition of $p_x$ in the ultrarelatavistic case.

Recognizing $\frac{m^2c^2}{p_o^2} = \frac{1}{\beta_o^2 \gamma_o^2}$ we can make one more simplification now that $\Phi = 0$, giving us the hamiltonian in Eq. \ref{eq:H_As}.

\begin{equation} \label{eq:H_As}
	H = -\left(1 + \frac{x}{\rho}\right)\sqrt{1 + p_t^2 - \frac{2 p_t}{\beta_o} - p_x^2 - p_y^2- } - \frac{p_t}{\beta_o} - \left(1 + \frac{x}{\rho}\right)\frac{q}{p_o}A_s
\end{equation}

The exact form of $A_s$ must now be selected to find our equations of motion. Before we do so we will consider the general form of this expansion we are interested in.

\section{Multipole Expansion} \label{sec:multipole}

To determine the fields used, we first consider what is convenient to generate. In general, a beam typically needs an evacuated beam pipe to travel in, so a we would like to consider magnetic fields that we generate outside of a region of beam travel. As a result we can consider a series solution for laplace's equtoins for magnetic fields in two dimensons for a region with periodic cylindrical boundary conditions, Eq. \ref{eq:poissonCylinder}

\begin{equation} \label{eq:poissonCylinder}
\begin{split}
	B_r(r,\theta) &= \sum_{n=1}^{\infty} C_n(z) \left( r \right)^{n-1} \sin{(n\theta)}\\
	B_\theta(r,\theta) &= \sum_{n=1}^{\infty} C_n(z) \left( r \right)^{n-1} \cos{(n\theta)}
\end{split}
\end{equation}

We can apply an alternative combined representation with complex variables introduced by Beth \cite{Beth} \ref{eq:bethCyl}.

\begin{equation} \label{eq:bethCyl}
	B_{\theta} + i B_r = \sum_{n=1}^{\infty} C_n(z) e^{in\theta} \left( r \right)^{n-1}
\end{equation}

Using the substitutions in Eq. \ref{eq:cylToCart} we can convert the field representation to cartesian coordinates which can be matched to our Hamiltonian coordinates \ref{eq:bethCart}.

\begin{equation} \label{eq:cylToCart}
\begin{split}
	B_{\theta} + i B_r &= B_y + i B_x\\
	r e^{i\theta} &= x + iy
\end{split}
\end{equation}

\begin{equation} \label{eq:bethCart}
	B_y + iB_x = \sum_{n=1}^{\infty} C_n(z) (x + iy)^{n-1}
\end{equation}

Of course, this expansion has been about a straight reference path which contrasts with our earlier transformation to the Frenet-Serret frame. There do exist treatments of multipoles defined in a curved reference frame \cite{ZolkinMultipole}, but this is of relatively minor concern. In practice, we can see that our dipole magnet is the only term which results in bending of the reference trajectory. So, these curved trajectory cases only are relevant inside an element with a deliberate dipole term. This brings up the notion of seperated and combined function machines. The first generation of machines used a fixed magnetic field for the entire radius, somtimes with short gaps for injection and extraction. Vertical focus either relied on the field falloff due to realistic magnet construction, or a deliberateley added gradient to the median plane, effectively a mixed dipole and quadrupole term in our multipole expansion. First generation alternating gradient accelerators kept this approach, simply implementing two types of "combined funciton" magnets with consistent dipole terms and alternating quadrupole terms for much stronger net focusing. It quickly became clear that it was preferrable to seperate the bending and focusing components of the fields for greater flexibility in design. As a result, in most modern machines exhibit bending only in pure dipole magnets and higher order fields are placed in straight sections. Combined function magnets are typically only used when particular cost or space concerns renders them more practical.

With regards to the 

An additional 

For the purposes of evaluating our Hamiltonian we can then represent the vector potential with respect to the multipole expansion terms.

Include sector vs rectangular bend consideration.
Seperated function and combined-function.
Comment on fringe field vs hard edge.
Vector potential expansion of multipoles.

\section{Linearized Hamiltonian} \label{sec:linHam}
Based on the form of the multipole expansion, we can see that only our dipole and quadrupole elements will affect the dynamics to the first order. While in general, we can use potentials of any order, we are not garanteed an analytical solution. The first order solutions to the equations of motion are possible to find analytically and will serve as the foundation for our dynamical analysis moving forward.

We will look for a solution to the equations of motion for a static quadrupole field. This has the vector potential in Eq. \ref{eq:As_B2}.

\begin{equation} \label{eq:As_B2}
	A_s = -\frac{B_2}{2}(x^2 - y^2)
\end{equation}

We also have no bending of the reference trajectory here so $\rho \rightarrow \infty$. Recalling our relationship for the rigidity $B\rho = \frac{p_o}{q}$ the resulting Hamiltonian is Eq. \ref{eq:H_q}

\begin{equation} \label{eq:H_q}
	H = -\sqrt{1 + p_t^2 - \frac{2p_t}{\beta_o} - p_x^2 - p_y^2} - \frac{p_t}{\beta_o} + \frac{k_2}{2}(x^2 - y^2)
\end{equation}

We will now make the first big assumption towards our solution. If we expand the square root term in the Hamiltonian and truncate to lowest order in the dynamical variables (Eq. \ref{eq:sqrt_taylor}) we are making the paraxial approximation. The argument is that since our cannonical momentum coordinates are all defined as a ratios with respect the the reference particle, when it is relatavistic the motion of these particles is all nearly parallel and these quantites are small, so higher orders can safely be ignored. Naturally this assumption breaks down for low energy beams, but is generally good for most practical accelerators.

\begin{equation} \label{eq:sqrt_taylor}
	\sqrt{1 + p_t^2 - \frac{2p_t}{\beta_o} - p_x^2 - p_y^2} \Rightarrow 1 - \frac{p_t^2}{2\beta_o^2\gamma_o^2} - \frac{p_t}{\beta_o} - \frac{p_x^2}{2} - \frac{p_y^2}{2} + O(3)
\end{equation}

Resubstituting and dropping the constant factor, we arrive at the Hamiltonian in Eq. \ref{eq:H_parax}

\begin{equation} \label{eq:H_parax}
	H = \frac{p_x^2}{2} + \frac{p_y^2}{2} + \frac{p_t^2}{2\beta_o^2\gamma_o^2} + \frac{k_2}{2}(x^2 - y^2)
\end{equation}

Note that the resulting hamiltonian has no mixed terms, so the equations are naturally seperated into the different dimensions. This is in part due to our selection of external field, if we selected a skew quadrupole the transverse dimensions would be coupled. We can see that any static multipole field will not result in any coupling to the longitudinal dimensions in the paraxial approximation. For the quadrupole the most relevant effect is the effective field for different momentum, the tansverse "Chromaticity" in analogy to light optics. This is properly treated at higher orders, but we will first resolve this to lowest order. Applying Hamilton's equations of motion gives us three systems of linear differential equations.

\begin{equation} \label{eq:quad_diffeq}
\begin{split}
	\frac{dx}{ds} &= p_x\\ 
	\frac{dp_x}{ds} &= -k_2 x
\end{split}
\end{equation}

Substituting and rearranging we arrive at Hills equation, Eq. \ref{eq:hills}

\begin{equation} \label{eq:hills}
	\frac{d^2 x}{ds^2} + k_2 x = 0
\end{equation}

Which has three general solutions for different ranges of $k_2$.

\begin{align} \label{eq:hillSol}
	x(s) &= a \cos{\left(\sqrt{k_2} s\right)} + b \sin{\left(\sqrt{k_2} s\right)}, &k_2>0\\
	x(s) &= a s + b, &k_2 =0 \\
	x(s) &= a \cosh{\left(\sqrt{k_2} s\right)} + b \sinh{\left(\sqrt{k_2} s\right)}, &k_2<0
\end{align}

For a quadrupole of a given lenth $L$, we can define a matrix Eq. \ref{mat:quad} which represents the three linear solutions for our different dimensions if it acts on a state vector of our canonical coordinates.

\begin{multline} \label{mat:quad}
	M_{quad} = \\
\begin{pmatrix} 
	&\cos{\left(\sqrt{k_2} L\right)} &\frac{1}{\sqrt{k_2}}\sin{\left(\sqrt{k_2} L\right)} &0 &0 &0 &0\\
	&-\sqrt{k_2}\sin{\left(\sqrt{k_2} L\right)} &\cos{\left(\sqrt{k_2} L\right)} &0 &0 &0 &0\\
	&0 &0 &\cosh{\left(\sqrt{k_2} L\right)} &\frac{1}{\sqrt{k_2}}\sinh{\left(\sqrt{k_2} L\right)} &0 &0\\
	&0 &0 &\sqrt{k_2}\sinh{\left(\sqrt{k_2} L\right)} &\cosh{\left(\sqrt{k_2} L\right)} &0 &0\\
	&0 &0 &0 &0 &1 &\frac{L}{\beta_o^2\gamma_o^2}\\
	&0 &0 &0 &0 &0 &1\\
\end{pmatrix}
\end{multline}

The same approach can be applied to our other seperated function, first order elements in the paraxial approximation, for a drift space (Eq. \ref{mat:drift}) and a sector dipole magnet (Eq. \ref{mat:dipole}).

\begin{equation} \label{mat:drift}
	M_{drift} =
\begin{pmatrix}
	&1 &L &0 &0 &0 &0\\
	&0 &1 &0 &0 &0 &0\\
	&0 &0 &1 &L &0 &0\\
	&0 &0 &0 &1 &0 &0\\
	&0 &0 &0 &0 &1 &\frac{L}{\beta_o^2\gamma_o^2}\\
	&0 &0 &0 &0 &0 &1\\
\end{pmatrix}
\end{equation}

\begin{multline} \label{mat:dipole}
	M_{dipole} = \\
\begin{pmatrix}
	&\cos{\left(\frac{L}{\rho}\right)} &\rho \sin{\left(\frac{L}{\rho}\right)} &0 &0 &0 &-\frac{\rho}{\beta_o}\left(1 - \cos{\left(\frac{L}{\rho}\right)}\right)\\
	&-\frac{1}{\rho}\sin{\left(\frac{L}{\rho}\right)} &\cos{\left(\frac{L}{\rho}\right)} &0 &0 &0 &-\frac{1}{\beta_o}\sin{\left(\frac{L}{\rho}\right)}\\
	&0 &0 &1 &L &0 &0\\
	&0 &0 &0 &1 &0 &0\\
	&\frac{1}{\beta_o}\sin{\left(\frac{L}{\rho}\right)} &\frac{\rho}{\beta_o}\left(1 - \cos{\left(\frac{L}{\rho}\right)}\right) &0 &0 &1 &\frac{\rho}{\beta_o^2}\sin{\left(\frac{L}{\rho}\right)} - L\\
	&0 &0 &0 &0 &0 &1\\
\end{pmatrix}
\end{multline}

Note that the dipole preserves coupling between the longitudinal and horizontal planes at the first order, unlike the quadrupole. This gives rise to first order dispersion, or longitudinally dependent energy coupling in the horizontal motion. 

These solutions are quite powerful, as they let us stack linear transformations in a row to construct mathematical representations of a transfer line. There is an additional advantage to this form, since the equations of motion were derived from the Hamiltonian of our system, we are garunteed that these transformations are symplectic. Formally a "symplectic form is a two-form which is closed and nondegenerate" \cite{JoseAndSalatan}. More usefully in a physics context a symplectic transformation is one which is garunteed to preserve our physical quantites, such as total energy. A sequence of symplectic mappings is also symplectic, so we can be certain that any sequence of our above matrix elements will maintain the symplectic condition. Symplecticity is a rich topic in the context of dynamical systems, but beyond the scope of this thesis, the author reccomends the following references for further edification.

\section{Courant-Snyder Parameterization} \label{sec:CSparam}
While the transformations we have aquired are generally applicable, we would like to evaluate the conditions for a stable periodic system like we need for a cyclic machine. At this point we will make another simplification of the dynamics by investigating the stability of the transverse and longitudinal dimensions seperately. This is of course not strictly true, but the characteristic timescales of synchrotron oscillations are often orders of magnitude slower than the transverse oscillations. We will choose the horizontal "x" motion to investigate. Analagous methods can be used for the "y" plane.

We begin with defining a matrix of a periodic "cell" (Eq. \ref{eq:period}), or sequence of elements $M_1 \dots M_n$ with total length $L$. This could be the representation of a whole cyclic accelerator, or smaller sequence of elements intended for a superperiodic construction.

\begin{equation} \label{eq:period}
	\mathbb{M}(s) = M(s+L|s) = M_nM_{n-1}\dots M_2M_1
\end{equation}

Our periodic condition then becomes that motion is bounded for repeated applications of this matrix. The solutions to Hills equations (including the dipole case where longitudinal coupling is excluded) yields matricies with a determinant of one. As the determinant of a product of matricies is the product of their individual determinants, we know that the determinant of our particular cell must be 1. If we decompose $\mathbb{M}$ into eigenvalues $\lambda_1, \lambda_2$ and eigenvectors $\vec{v}_1, \vec{v}_2$, the unit determinant leads to two useful relationships. First $\lambda_1 + \lambda_2 = \mathrm{Trace}(\mathbb{M})$, and second $\lambda_1 = 1/\lambda_2$. Substituting and rearranging yields Eq. \ref{eq:eigenTrace}.

\begin{equation} \label{eq:eigenTrace}
	\lambda_1^2 - \mathrm{Trace}(\mathbb{M})\lambda_1 + 1 = 0
\end{equation}

If we describe a cannonical state vector as a linear combination of our eigenvectors we can get a straightforward requirement on our eigenvalues with repeated application of the transfer map (Eq. \ref{eq:eigenRep}).

\begin{equation} \label{eq:eigenRep}
	\vec{q}_n = \mathbb{M}^n\vec{q}_o = \mathbb{M}^n(a \vec{v}_1 + b \vec{v}_2) = a \lambda_1^n \vec{v}_1 + b \lambda_2^n \vec{v}_2
\end{equation}

This relationship clearly demonstrates that for stable long term motion, these eigenvalues cannot grow with repeated iterations. Courant and Snyder proposed the following general parameterization of our transfer matrix in Eq. \ref{eq:csMat}.

\begin{equation} \label{eq:csMat}
	\mathbb{M}_{CS} = 
\begin{pmatrix}
&\cos{\left(\phi_x\right)} + \alpha_x\sin{\left(\phi_x\right)} &\beta_x\sin{\left(\phi_x\right)}\\
&-\gamma_x\sin{\left(\phi_x\right)} &\cos{\left(\phi_x\right)} - \alpha_x\sin{\left(\phi_x\right)}\end{pmatrix}
\end{equation}

If we calculate the trace of this parameterization and substitute into Eq. \ref{eq:eigenTrace}, we find values of the eigenvalues to be Eq. \ref{eq:eigenSol}

\begin{equation} \label{eq:eigenSol}
\begin{split}
	\lambda_1 &= e^{i\phi_x}\\
	\lambda_2 &= e^{-i\phi_x}\\
\end{split}
\end{equation}

Where $\phi_x$ is complex if $|\mathrm{Trace}(\mathbb{M})| > 2$ and real if $|\mathrm{Trace}(\mathbb{M})| < 2$. We can see from Eq. \ref{eq:eigenRep}, our motion is only bounded for real values of $\phi_x$ and our stability condition for a periodic transfer matrix $\mathbb{M}$ becomes $|\mathrm{Trace}(\mathbb{M})| < 2$.

By leveraging the fact that the periodic linearized equations of motion have a determinant of 1, we can arrive at the relationship in Eq. \ref{eq:csRel}. We can also see from the couraunt snyder parameterization Eq. \ref{eq:phiTrace} holds for any stable transfer matrix. This defines the fractional component of $\phi_x$, but leaves it ambiguous to integer multiples of $2\pi$. In practice, the ambiguity can be cleared up by calculating this parameter for individual constituents of the periodic transfer matricies.

\begin{equation} \label{eq:csRel}
	\beta_x \gamma_x  = 1 + \alpha_x^2
\end{equation}

\begin{equation} \label{eq:phiTrace}
	\cos{\left(\phi_x\right)} = \mathrm{Trace}(\mathbb{M})
\end{equation}

We can further investigate the form of these parameters by splitting the general periodic matrix, in Eq. \ref{eq:csMatSplit}, where the matrix $A$ and $S$ are given in Eq. \ref{mat:csA}. $S$ is a block antisymmetric matrix, and reduces to just the antisymmetric matrix in two dimensions like we have here.

\begin{equation} \label{eq:csMatSplit}
	\mathbb{M}_{CS} = I \cos{\left(\phi_x\right)} + S A \sin{\left(\phi_x\right)}
\end{equation}

\begin{equation} \label{mat:csA}
	A = 
\begin{pmatrix}
	&\gamma_x &\alpha_x\\
	&\alpha_x &\beta_x
\end{pmatrix},
\hspace{10pt} S =
\begin{pmatrix}
	&0 &1\\
	&-1 &0
\end{pmatrix}
\end{equation}

Within our periodic cell $\mathbb{M}$, we can consider the transformation in Eq. \ref{eq:startShift} by some transfer matrix in the cell which moves the overall start point. By examaning the trace of this transformation, we can see that $\phi_x$ of our periodic matrix is unchanged by this shift in start point.

\begin{equation} \label{eq:startShift}
	\mathbb{M}(s_1)  = M(s_1|s_o)\mathbb{M}(s_o)M(s_1|s_o)^{-1}
\end{equation}

If we apply this transformation to \ref{eq:csMatSplit}, as $\phi_x$ unadjusted by the shift, the overall effect is summarized in Eq. \ref{eq:AstartShift}.

\begin{equation} \label{eq:AstartShift}
	S A(s_1) = M(s_1|s_o) S A(s_o)M(s_1|s_o)^{-1}
\end{equation}

We can now leverage the underlying symplecticity of our transfer matricies, which mandates the condition in Eq. \ref{eq:symplecticMat}.

\begin{equation} \label{eq:symplecticMat}
	M^T S M = S
\end{equation}

Recognizing that $S^T = S^{-1}$ and using the symplectic condition, we can rarrange and invert Eq. \ref{eq:AstartSplit} to arrive at the transformation of $A^{-1}$ at different points in the cell in Eq. \ref{eq:barAshift} 

\begin{equation} \label{eq:barAshift}
	A(s_1)^{-1} = M(s_1|s_o)  A(s_o)^{-1} M(s_1|s_o)^T
\end{equation}

After inverting $A$ we can solve Eq. \ref{eq:barAshift} for the transformation of our courant-snyder parameters $\beta_x, \alpha_x, \gamma_x$ with respect to the components of the transfer matrix $M$ in eqation Eq. \ref{eq:csShift}.

\begin{equation} \label{eq:csShift}
	\begin{pmatrix} &\beta_x(s_1) \\ &\alpha_x(s_1)\\ &\gamma_x(s_1) \end{pmatrix} = 
	\begin{pmatrix}
		&M_{11}^2 &-2 M_{11} M_{12} &M_{12}^2\\
		&-M_{11} M_{21} &M_{11} M_{22} + M_{12} M_{21} &-M_{12}M_{22}\\
		&M_{21}^2 &-2 M_{21} M_{22} &M_{22}^2
	\end{pmatrix}
	\begin{pmatrix} &\beta_x(s_o) \\ &\alpha_x(s_o)\\ &\gamma_x(s_o) \end{pmatrix}
\end{equation}

This is a useful result, as it means for any stable, periodic, sequence of our linear beamline elements, we can uniquely define the courant snyder parameters and transfer them to any other point in the lattice. The result in \ref{eq:csShift} is even useful without a periodic system, as the effective lattice parameters of a beam distribution (described later in this section) can be transformed along a sequence of linear elements as is the case in a linac or transfer line.

We would now like to find the equations of motion for this parameterization. We can construct an invariant action for our canonical coordinates and Courant-Snyder parameters.

\begin{equation} \label{eq:csJ}
	J = \frac{1}{2} (\vec{q}_x)^T A \vec{q}_x = \frac{1}{2} (\gamma_x x^2 + 2\alpha_x x p_x + \beta_x p_x^2)
\end{equation}

Which we verify is invariant by inspecting the transformation of our cannonical state vectors $\vec{q}_X$ and matrix $A$ under a transfer matrix.

\begin{equation} \label{eq:Jinvariant}
	J(s_1) = \frac{1}{2} \vec{q}_x(s_1)^T A(s_1) \vec{q}_x(s1) = \frac{1}{2} \vec{q}_x(s_o)^T M^T (M^T)^{-1} A(s_o) M^{-1}  M \vec{q}_x(s_o) = J(s_o)
\end{equation}

Determining the angle variable with respect to the cournant snyder parameters is an extended derevation which requires inspecting the general solution to Hill's equation using the Floquet transform in comparison with the current periodic condition. This would be longer than the entire derevation of the courant snyder parameters up to this point, so it is ommitted here and only the important results are quoted. First the relationship to the angle variable $\varphi_x$ to the coordinates.

\begin{equation} \label{eq:csAngle}
	\tan{(\varphi_x)} = -\beta_x \frac{x}{p_x} - \alpha_x 
\end{equation}

Second, the relationship to the $\beta_x$ parameter, to the focusing term $K(s)$ in Eq. \ref{eq:floqetBet}. Here $K(s)$ is a stand in for all of our Hill's equation conditions, both focusing and defocusing and the weak focusing effect from dipoles. 

\begin{equation} \label{eq:floqetBet}
	\begin{split}
	&\frac{d^2}{ds^2}\sqrt{\beta_x(s)} + K(s)\sqrt{\beta_x(s)} = \frac{1}{\sqrt{\beta_x^3(s)}} \hspace{5pt} or,\\ 
	&\frac{\beta_x(s)}{2}\frac{d^2\beta_x(s)}{ds^2} - \frac{1}{4}\left(\frac{d\beta_x(s)}{ds}\right)^2 + K(s)\beta_x^2(s) = 1
	\end{split}
\end{equation}

Third we can recognize an additional relationship between the $\alpha_x$ and $\beta_x$ functions in Eq. \ref{eq:alphaToBet}

\begin{equation} \label{eq:alphaToBet}
	\alpha_x(s) = -\frac{1}{2}\frac{d\beta_x(s)}{ds}
\end{equation}

Finally we can relate the angle variable to the $\beta_x$ function (Eq. \ref{eq:varphiBet}) and our phase advance $\phi_x$ (Eq. \ref{eq:phiBet}.

\begin{equation} \label{eq:varphiBet}
	\frac{d\varphi_x(s)}{ds} = \frac{1}{\beta_x(s)}
\end{equation}

\begin{equation} \label{eq:phiBet}
	\phi_x(s_1|s_o) = \varphi(s_1) - \varphi(s_o) \Rightarrow \phi_x(s_1|s_o) = \int_{s_o}^{s_1} \frac{1}{\beta_x(s)} ds
\end{equation}

The result is that we only need the function $\beta_x(s)$ and its derivative to fully parameterize the linear motion of our single particles in an accelerator. We can further expand on this by finding the equations of motion with respect to this phase angle $\varphi_x$ by inverting Equations \ref{eq:csAngle} and \ref{eq:Jinvariant} to arrive Equations \ref{eq:csXvarphi} and \ref{eq:csPvarphi}.

\begin{equation} \label{eq:csXvarphi}
	x = \sqrt{2 \beta_x J_x} \cos{(\varphi_x)}
\end{equation}

\begin{equation} \label{eq:csPvarphi}
	p_x = -\sqrt{\frac{2 J_x}{\beta_x}} (\sin{(\varphi_x)} + \alpha_x \cos{(\varphi_x)})
\end{equation}

We can see that the combination of these equations of motion paramaterize a ellipse for our poincare section at any given point along the beamline. Figure \ref{fig:csEllipse} shows such an ellipse with the relevant relationship to the Courant-Snyder parameters. The area of this ellipse is $2\pi J_x$, but is ususally related to the "emittance" in Eq. \ref{eq:csEmit} as $\pi \epsilon_x$. There is some inconsistency in application of the emittance in accelerator literature, sometimes it is only considered to be an aggregate property of a particle bunch and other times it may relate to a single particle equivalent dynamical value. I will distiguish the aggregate property as e.g. $\epsilon_{x,rms}$, defined in section \ref{sec:bunchEmit}, to disginguish it from the dynamical value $\epsilon_x$.

\begin{equation} \label{eq:csEmit}
	\epsilon_x = 2 J_x
\end{equation}

\begin{figure} \label{fig:csEllipse}
	\centering
	\includegraphics[width=\linewidth]{phase_space_ellipseImpactX.pdf}
	\caption{Poincare section ellipse of linear betatron motion with associated relationships to Courant-Snyder parameters \cite{ImpactX}}
\end{figure}

We can see that there is additional intuitive value to the $\beta_x$ function, as it describes the envelope of motion for the lattice at a given location. Additionally, the phase advance $\phi_x$ can be seen as sort of betatron oscillation time parameter. Regions with small beta functions, or small beam envelopse have large phase advances and represent large advances in the betatron oscillations. Based on this result we can introduce the "normalized" (they still have dimension of $\sqrt{m}$) Cournat-Snyder parameters in \ref{eq:csNorm}.

\begin{equation} \label{eq:csNorm}
\begin{split}
	x_N &= \frac{x}{\sqrt{\beta_x}}\\
	p_{xN} &= \frac{\alpha_x x}{\sqrt{\beta_x}} - \sqrt{\beta_x}p_x
\end{split}
\end{equation}

This normalization reduces the equations of motion to that of circles with radius equal to the square root of the emittance. These coordinates are also sometimes referred to as floquet coordinates in accelerator literature.

\begin{equation} \label{eq:csNormVarphi}
\begin{split}
	x_N &= \sqrt{\epsilon_x} \cos{(\varphi_x)}\\
	p_{xN} &= -\sqrt{\epsilon_x} \sin{(\varphi_x)}
\end{split}
\end{equation}

We can also observe that the definition of the emittance simplifies in these coordinates (Eq. \ref{eq:csNormEmit}), and our linearized Hamiltonian reduces to Eq. \ref{eq:csNormHam}.

\begin{equation} \label{eq:csNormEmit}
	\epsilon_x = p_{xN}^2 + x_{N}^2
\end{equation}

\begin{equation} \label{eq:csNormHam}
	H = \frac{p_{xN}^2}{2\beta_x} + \frac{x_{N}^2}{2\beta_x}
\end{equation}

All of this parameterization was of course in one dimension, the same can be applied to the y-plane assuming they are uncoupled. An extended parameterization to include coupling has been considered and there are two main approaches. One by Edwards-Teng \cite{edwards-teng} and one by Mais-Ripkin \cite{mais-ripkin} with extensions by Lebedev-Bogacz \cite{lebedev-bogacz}. A good overview is provided in \cite{vanwelde}. For the purposes of this thesis these coupled parameterizations are extraneous and only affect the tune match possible which will be discussed in chapter \ref{chap:experiment} on experimental design.

The beta funciton is strictly positive

At this point I would like to reiterate the assumptions along the way and comment on their impacts.

This approach has been very powerful and is the guiding principle for first order accelerator design since its introduciton. There is a wide variety of lattice simulation codes dating back to the 60's specifically designed to calculate these lattice parameters for evaluating stability, steering, and aperture restricitons of linear lattices.

\section{First Order Bunch Properties} \label{sec:bunchEmit}
In practice we rarely accelerate single particles, and so we would like to parameterize the collective properties of the particle bunch. If we have some bunch of particles all undergoing betatron oscillations we can relate their individual oscillations to the ensemble average or first moment in Eq. \ref{eq:bunchMean}.

\begin{equation} \label{eq:bunchMean}
	\langle x \rangle  = \sqrt{\beta_x} \langle \sqrt{\epsilon_x} \cos{(\varphi_x)}\rangle 
\end{equation}

Here we can extract the beta funciton since we know it is a longitudinally dependent parameter of the lattice and not our individual particles. For a typical bunch we can assume a uniform distribution of oscillation phases, and we know from our equations of motion that the emittance and betatron phase are uncorrolated, so we can see that this mean is typically zero. This form can be exploited by adding a coherent correlated emittance and phase term to the bunch with a "Kicker" element. This adds a coherent term to Eq. \ref{eq:bunchMean} and we can observe the bunch centroid evolving according to the lattice dynamics. If we look at the second moments we can extract more information on the bunch distribution. We start with the transverse coordinate, Eq. \ref{eq:momX2}.

\begin{equation} \label{eq:momX2}
	\langle x^2 \rangle = \beta_x \langle \epsilon_x \cos{(\varphi_x)}^2 \rangle
\end{equation}

If we evaluate again for a uniform distribution of the betatron phase, we arrive at Eq. \ref{}

\begin{equation} \label{eq:emitDef}
	\langle x^2 \rangle = \frac{\beta_x}{2} \langle \epsilon_x \rangle
\end{equation}

We then define our rms emittance in Eq. \ref{eq:rmsEmit}. 

\begin{equation} \label{eq:rmsEmit}
	\epsilon_{x,rms} = \frac{1}{2} \langle \epsilon \rangle
\end{equation}

Using the same approach, we can relate the emittance to the two other moments of the distribution.

\begin{equation} \label{eq:momP2}
\begin{split}
	\langle x p_x \rangle &= -\alpha_x \epsilon_{x,rms}\\
	\langle p_x^2 \rangle &= \gamma_x \epsilon_{x,rms}
\end{split}
\end{equation}

Based on the relationship between the courant-snyder parameters in Eq. \ref{eq:emitMoment}.

\begin{equation} \label{eq:emitMoment}
	\epsilon_{x,rms} = \sqrt{\langle x^2 \rangle \langle p_x^2 \rangle - \langle x p_x \rangle^2}
\end{equation}

These parameters,

\section{Integrable Systems} \label{sec:integral}
The Courant-Snyder parameterziation is an example of an integrable dynamical system.
emmitance preservation allows for parameterizaion and bounded orbits
Long history of searching for integrable systems

\section{Nonlinear Integrable Optics} \label{sec:nio}


\cite{danilov_nonlinear_2010}
