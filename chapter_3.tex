\chapter{Experimental Analysis} \label{chap:analysis}


\section{Tune Measurements} \label{sec:tune}
Tune measurments provide long term coherent information on the dynamics and the strong dependence on amplitude is the chief experimental indicator of nonlinearities in the focusing. While decoherence limits the available turns for measurments, the variations in amplitude do not alter the fundamental frequency, which gives us a longer coherent signal. The tune was previously defined only for the linear system in the context of phase advance. The definition of the tune is more nebulous then for a strongly nonlinear system, as the motion is neccesarially anharmonic. For nonlinear dynamical systems, the poincare rotation number is a related quantity \cite{nagaitsevBetatron}, but difficult to relate to measurable quantities. For the experimental measurments, we interpret the dominant frequency of the transverse oscillation spectrum as the tune. 

Different tune measurment algorigthim were considered for the particular limitations of the available data. The simplest approach is simply taking the Fourier transform of turn by turn (TBT) BPM data and picking the peak frequency. As we have discrete sampling of the motion, a discrete Fourier transform is a simple first approach. Practically, the fast fourier transform (FFT) is used as the default discrete transform. There are a number of methods to improve the resolution of the frequency measurements. In principle a windowing function can be applied to improve resolution of the peak frequency at the cost of supressing sidebands. However, for the IOTA data, there are two important considerations. A window suppresses the amplitude of a fraction of the sample window. In the case of the short coherent measurments, the reduction in available signal was more detrimental than the advantages of the window. And for low signal to noise ratios the benefits of a window disappear. For example, the common Hann window does not provide any benefits for signal to noise ratios less than \num{1e3} \cite{bartoliniAlgorithms}, well above those seen in IOTA. To bypass some of the limitations on the disctrete sample resolution of the FFT, Jacobsen interpolation \cite{jacobesnLocla} applies a quadratic interpolation to the FFT peak and its nearest neighbors for finer peak resolution. The implementation used is based on that from the PyLHC \cite{cernomc} analysis library. The other approach considered is the Numerical Analysis of Fundamental Frequencies (NAFF) proposed by Lasker for the evaluation of long term stability of planetary systems \cite{laskar}. NAFF starts with a guess from the FFT spectrum, and seeks to iteratively optimize the magnitude of a single fourier transform as in equation \ref{eq:naff}. In principle this can be used to extract successive harmonics of the motion, but we are interested only in the dominant frequancy, so typically only one term is considered. The implementation of NAFF used in this analysis is PyNAFF \cite{zisopolusPZ}, this uses hardys method (Eq. \ref{eq:hardy} \cite[p.151]{whitakerCalculs}) for the numerical integration as opposed to a simple riemann summ. In addition to the offline methods, live tune measurments on circulating beam used a least squares approach, where an assumed functional form with free parameters for tune, phase, coupling, and decoherence times, is fit to the data.

\begin{equation}
	\Psi(T) = \frac{1}{2T}\int_{-T}^{T}f(t)e^{-i\omega t}dt
	\label{eq:naff}
\end{equation}

\begin{equation}
	\int_{x_{n}}^{x_{n+6}}f(x)dx \approx \frac{\Delta x}{100}\left(28(f(x_n) + f(x_{n+6})) + 162(f(x_{n+1}) + f(x_{n+5})) + 220 f(x_{n+3}) \right)
	\label{eq:hardy}
\end{equation}

To evaluate the methods, a comparison was made with both a synthetic signal and the simulated bunch centroid signal from an Impact-X simulation. Figure \ref{fig:synKicks} shows the evaluation signals, the amplitude does not impact the tune evaluation. The synthetic signal consisted of a convolution of a single harmonic base signal, a logistic function for decoherence and a gaussian noise distribution with a RMS of ten percent of the signal amplitude. 

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/syntheticAndSimulationKicks.pdf}
	\caption{Evaluation signals, fully synthetic and simulated}
	\label{fig:synKicks}
\end{figure}

The first evaluation was on the convergence of the various methods. Figure \ref{fig:baseConv} shows the convergence of tune measurments for the various considered algorighms with increasing length of the sample window. The limitations of the FFT resolution from the available signal are clear, but they inform the initial values for the interpolation and the NAFF. The vertical simulation signals are considered here as they exhibit faster decoherence. The relatively long coherence time of the horizontal signal means that convergence rate is less important, and we are interested in best performance for very fast decoherence.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/basicConvergence.pdf}
	\caption{Convergence of tune measurments with lenght of signal window}
	\label{fig:baseConv}
\end{figure}

The available resolution of the FFT can be improved by padding the input signal with zero values. This is the same effect as increasing the lenght of the signal and applying a rectangular window the length of the original signal. Figure \ref{fig:padConv} shows the convergence of the faster methods with and without padding. Here all signals were padded to an equal signal lenght of 256 turns. We see that the convergence of the padded FFT is improved, but the windowing effect introduces a systematic, limited offset of the tune determined by the lenght of the padding. The Jacobsen interpolation with a padded signal also suffers a similar effect, converging on a systematically offset tune.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/paddedConvergence.pdf}
	\caption{Convergence of tune measuremnts with zero padding}
	\label{fig:padConv}
\end{figure}

We then have three approaches which reliably converge before the 100 turn limit of our sample plots, Jacobsen interpolation wihtout padding, and NAFF with and without padding. In evaluating the quality of the convergence, the noise seed on the simulated signal was found to have a significant effect on these methods. The convergence of the tune measurement was evaluated for the same underlying synthetic signal and decoherence as before but with one thousand different noise seeds for the random noise. The synthetic signal was used as there is a garuntee of a single underlying frequency unlike the simulation signal. The ensemble properties of the convergence are plotted in Figure \ref{fig:noiseConv}. The left plot shows the mean of the absolute difference of the measured tune from the nominal, $|Q_{meas} - Q_{nominal}|$ and the right plot is the standard deviation of the measured tunes for each window lenght. We see that the average convergance is about the same, with a slight prefereance for Jacobsen interpolation. The padded NAFF measurements have slightly lower variation.


\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/noiseSeedConvergence.pdf}
	\caption{Convergence of tune measuremnts with zero padding}
	\label{fig:noiseConv}
\end{figure}

There is an additional consideration, we can evaluate the accuracy of the measurments while adjusting the inital phase. There is a periodic variation of the measured tune for this change in initial.  This neccesarally means sampling a lower amplitude region of the signal as you go along the decoherence. With the padded signal we can also do a similar transfomation. By rolling the padding to the front as well as behind with the same overall signal lenght, different phases given by the resoltion of the binning. Figure \ref{fig:baseRoll} shows the change in the tune measurments for varying the initial turn of a sixty turn sample window and "rolling" the padded signal. Note that the first value of the NAFF padded and the NAFF rolled circled in black are exactly the same as they are evaluating the same signal. This comparison is not apples-to-apples but it does imply a benefit of the NAFF padded evaluation. For a given signal lenght the uncertianty due to the initial phase is regular and can be evaluated without sampling different, presumamby lower amplitude areas of the original signal.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{./chapter_3_figures/slideTuneComparison.pdf}
	\caption{Variaiton of tune measurments with inital phase}
	\label{fig:baseRoll}
\end{figure}

The different tune measurement algorithms have different characteristic statistical uncertianties that scale with the availible sample window. Without interpolation, the uncertianty in the FFT lines goes as $\frac{1}{N}$ where N is sample points, in our case available turns. Both the unwindowed NAFF and interpolation approaches have analytic uncertianties that go as $\frac{1}{N^2}$ \cite{zisopolousRefined,bartoliniTune}. The magnitude of the variation due to initial phase was added to the uncertianty of the tune measurements. We then have the following steps for a single signal tune measurement:

\begin{enumerate}
	\item{Zero pad signal to predetermined length}
	\item{Evaluate the tune with NAFF}
	\item{"Roll" the signal to shift inital phase}
	\item{Evaluate rolled signal with NAFF}
	\item{Repeat roll and evaluation a predetermined number of times, and estimate initial phase uncertianty from variance in rolled tune measurments}
\end{enumerate}

This algorightm is applied to the real TBT bpm sample (Figure. \ref{fig:realEvalSig}) in  Figure \ref{fig:measConvRoll}.

\begin{figure}
	\centering \includegraphics[width=1\linewidth]{./chapter_3_figures/realTuneEvalSignal.pdf}
	\caption{Example kick for tune evaluation, BPM B1R signal}
	\label{fig:realEvalSig}
\end{figure}


\begin{figure}
	\centering \includegraphics[width=1\linewidth]{./chapter_3_figures/realTuneConvergence.pdf}
	\caption{Tune measurment convergence for measured TBT data, with estimated uncertianty}
	\label{fig:measConvRoll}
\end{figure}


The above comparisons assume a single signal, but multiple BPM signals are available and we would like to combine them, there were two approaches considered. The first is a BPM stacking approach, where a quasi-periodic signal is constructed \cite{zisopolousRefined} by stacking sequential BPMs. This approach did not yield good results for the experimental IOTA data.

The other considered approach to investigate multiple BPM response was to select the dominat components of a PCA decomposition of all combined BPM signals. PCA was selected as the scikit-learn implementation of PCA was significantly more performant than the numpy implementation of SVD, with the same resulting singular values. Figure \ref{fig:pcaComps} shows the matrix resulting from the convolution of the BPM-specific terms in the PCA with the singular values of a single kick, the same kick as shown in \ref{fig:realEvalSig}. Each column corresponds to a BPM, with the center line indicating the split between the horizontal and vertical BPM labels. 

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{./chapter_3_figures/t238_singleKickPCA.pdf}
	\caption{PCA decomposition of TBT signals }
	\label{fig:pcaComps}
\end{figure}

The rows indicate different temporal signals. To provide some insight, in the case of simple harmonic motion we would expect four terms, two components for each phase in each plane. Each BPM signal is then composed of the relevant fraction of these phase components with scaling proporitonal to the beta function at that location. Figure \ref{fig:pcaTemps} shows the first four temporal components of the same decomposition. 

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/pcaTemporalModes.pdf}
	\caption{First four PCA temporal modes from decomposition above}
	\label{fig:pcaTemps}
\end{figure}

We can then discriminate on the direction of a tune component by looking at the relative magnitudes of the temporal components in the horizontal and vertical BPMs. A tune measurement technique, NAFF in this case, can then be applied to these individual components. This has the slight drawback of making phase measurments of individual BPMs more difficult, but this is not typically considered the the analysis anyways. 

Another effect on tune measurements is resonant capture, where a small fraction of the beam becomes trapped in a resonant condition and continues to oscillate at the characteristic frequency of the resonance. As the rest of the beam quickly decoheres due to tune spread, this dominates tune measurements with long sample windows. This can be seen in the spectrogram with short vertical decoherence with a long faint line. Figure \ref{fig:resCapReal} shows the profile for a kick demonstrating resonant capture. The vertical decoherence is very fast, about 20 turns. However, a small portion of the beam continues to coherently oscillate as can be seen in the spectogram in Figure \ref{fig:specResCap}. This spectogram has a window lenght of 60 turns. The dominant peak in the first window is with the decohering main tune line, but we see a faint line with one bin lower tune and long coherence right on the third order difference line $Q_x-2Q_y = 0$.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/resonantCaptureSignal.pdf}
	\caption{Example resonant capture kick}
	\label{fig:resCapReal}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/resonantCaptureSpectogramB1R_238_10_19_kick26.png}
	\caption{Resonant capture spectogram}
	\label{fig:specResCap}
\end{figure}

This resonant capture effect means we prefer to keep the tune measurment windows as short as gives reasonable tune resolution. This effect has been demonstrated in simulation, with kicked bunch measurements, and can be seen in single-electron measurments.

\section{Nonlinear Insert Calibration} \label{sec:nioCal}
The nonlinear insert had to be calibrated and aligned to best match the nominal potential. This was done with beam based measurments. Recalling from section \ref{sec:dnMag} that the lowest order component of the nonliner insert is a quadrupole, and that the proper implementation of the DN NIO system requires consistent longitudinal scaling to properly match the potential, we treat the individual DN magnets as quadrupoles for small amplitudes. LOCO was applied to center the individual elements, the measured closed orbit offsets after centering \textit{assuming quadrupole terms} are presented in \ref{fig:dnOffset}. 

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{./chapter_3_figures/dnOrbitOffsets.pdf}
	\caption{Closed orbit offests in DN magnet after manual alignment, assuming quadrupole terms}
	\label{fig:dnOffset}
\end{figure}


Each magnet was energized individually and a small amplitude kick was applied to the beam to measure the tune shift. This was done for multiple current setpoints to fit a tune shift vs current.
The individual scaling of the nonlinear t-parameter to current was calibrated for each magnet using the tune shift due to a quadrupole error in the lattice, (eq. \ref{eq:quadErrShift}) set equal to the quadrupole term of the DN potential (eq. \ref{eq:dnQuadTerm}), and solved for t.

\begin{equation}
    	\Delta Q_{x} = \pm \frac{1}{4\pi}\int{\beta_x(s) \frac{\Delta B_2}{B\rho} ds}
    	\label{eq:quadErrShift}
\end{equation}

\begin{equation}
	\Delta B_2 = \frac{-2B\rho \Delta t}{\beta^2(s)}
	\label{eq:dnQuadTerm}
\end{equation}

The resulting data gives a relative current scaling profile for the overall insert Fig. \ref{fig:dnIscaling}. This calibration assumes good accuracy of the beta functions in the nonlinear insert at the time of the calibration.

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{./chapter_3_figures/2023-05-22dnScalings.pdf}
    \caption{Relative DN insert current scaling profile compared to calculated ideal values}
    \label{fig:dnIscaling}
\end{figure}

This approach gives good relative scaling of the magnets, but we want to additionally evaluate the calibration of the insert as a whole. The tune shift assuming only the quadrupole terms of the DN element is given in Eq. (\ref{eq:dnDetune}) \cite{nagaitsevNonlinearOptics}.

\begin{equation}
	\begin{split}
	Q_{x} = Q_{o}\sqrt{1+2t} \\
        Q_{y} = Q_{o}\sqrt{1-2t}
	\end{split}
	\label{eq:dnDetune}
\end{equation}

The tune shift of the insert was measured by adjusting the t-parameter of the entire DN insert, according to the previously calibrated current ratios and kicking the beam to small amplitudes to measure the tune. The measured tunes are plotted with the quadrupolar detuning in Figure \ref{fig:dnDetuning}. The impact of the sextupoles used to compensate chromaticity can be seen inas the dominant effect on the tune near the third order resonances (red lines on tune diagram).

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/tuneSpaceDnShift.pdf}
    \caption{Measured nonlinear insert tune shift detuning}
    \label{fig:dnDetuning}
\end{figure}

The ratio of the tune shift between the planes is good indicator of proper implementation of the longitudinal scaling of the potenetial and beta function match in the insert. The absolute t-parameter scaling was calibrated by measuring tune shift vs nominal t-parameter, as presented in Figure \ref{fig:dnTuneVsT}. The gap in the data between t=0.2 t=0.3 was an unfortunate result of the BPM system freezing and failing to update TBT data, and was simply excluded.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/dnDetuningCalFactor.pdf}
    \caption{Tune shfit vs t-parameter in both planes, before and after scaling}
    \label{fig:dnTuneVsT}
\end{figure}

The initial data indicated a discrepancy in the tune dependence of the t-parameter. The proportiona The ideal detuning expression was fit to the data with a t-scaling factor as the only free parameter Eq. (\ref{eq:fitTune}). 

\begin{equation}
    Q = Q_o \sqrt{1\pm 2at}
    \label{eq:fitTune}
\end{equation}

The fit resulted in a calibrated t-parameter scaling of $a \approx 0.935$. The source of this discrepancy is not clear, but may be a result of magnet crosstalk, as the relative calibration was measured with single elements and the magnet spacing is close.

\section{Momentum Reconstruction} \label{sec:momReconst}
For studying the evolution of the phase space, the four dimensional $(x,p_x,y,p_y)$ transverse coordinates of the beam need to be reconstructed. There are a few standard ways to accomplish this. The simplest approach is a pair of BPMs with a $\phi = \pi/2$ phase advance between them. This is a straightforward start, but we have more than two BPMs and would like to combine the signals. A succesful approach this is the N-BPM method \cite{langerOptics}, which can reconstruct the momentum from measured beta functions. The most accurate beta function measurements use the relative phase advance between BPMs can adjust a model prior for the betas. In the case of IOTA with the NIO insert, the tune and therefore phase advance is highly nonlinear and not a reliable parameter to combine with the bare lattice. Instead we leverage the linear model of the lattice generated using LOCO. The momentum and position at a virtual BPM could then be reconstructing using a least squares approach. 

The BPMs are all located in the linear matching section of the lattice. We can then reconstruct the position and momentum at a virtural BPM turn by turn, using the linear model from LOCO. The main nonlinearity in IOTA stems from the insert, though there is nonlinearity stemming from the sextupoles, fringe fields, and sharp bending dipoles. Using higher order maps including the calibrated sextupole terms was considered, but expanding the method using second order transfer maps yielded poor convergence of the fits of the motion. Additionally, such a method would require more accurate understanding of the residual nonlinearities in the matching lattice than we currently have for IOTA. We have an advantage in that the nonlinear effects outside of the insert are perturbative compared to the linear focusing terms, so we only expect them to be coherent over many turns. This motivates carefully evaluating the goodness of fit to our linear model later in this section. So then, for the fitting, the matching section was essentially treated in a channel mode from the end of the nonlinear insert to the beginning of it.

To perform the least squares fit the lmfit python package \cite{newvilleLMFIT} was used. The nonlinear least squares efforts are irrelevent for the linear transport model, but the interface is much improved over other pythonic options, e.g. scipy. For our fits the free parameters are the position and momentum at a virtual BPM. Our model is the linear transfer matrices to each BPM from the virtual BPM location. In principle, these could be coupled, but the coupling is deliberatley locally corrected with the IOTA skew quad correctors. The resulting transfer matrices have coupling on the order of the machine precision, so we simply exclude these terms to reduce the dimensionality of the fit. Accordingly, we perform a fit for each plane. The data for the fit is the BPM measured position at each BPM in a given turn. To ascribe an uncertianty to our reconstructed coordinates we need an understanding of the uncertianty in our BPM measurements.

The uncertianty of the BPM measurements is evaluated from the variation in the tails long after the signal has fully decohered. Note that the radiation damping time for the beam ~3 orders of magnitude longer than this sample time. The individual particles are still at mostly full amplitude and our beam is "large". This may impact the centroid measurments if the nonlinear BPM calibration factors are off, as a fraction of the beam near the buttons may be undersampled or saturate the acquisition electronics. Some preprocessing was applied to the BPM signals to excluded these effects. For NIO lattice configurations, the tail was defined to be 2000 turns from the end, well past the expected coherence limit. Figure \ref{fig:bpmErrCutoff} shows the full sample range of an example kick in IOTA with a line indicating the noise sample threshold.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/exampleKick_pointDN_t238.pdf}
    \caption{Full range IOTA example kick with error estimation cutoff}
    \label{fig:bpmErrCutoff}
\end{figure}

The error in the BPM measurments is then evaluated to be the variance in this remaining signal. Figure \ref{fig:bpmErrIQR} shows the histogram of coordinates in the last thousand turns in Figure \ref{fig:bpmErrCutoff}. The standard deviation and interquartile range are both calculated and compared. The interquartile range is less susciptible to outliers, and can be directly related to the standard deviation if the distribution is gaussian. A comparison of these metrics for a large sample of real IOTA kicks showed good correspondence, indicating that the bpm noise is well modeled with the normal distribution. For fitting, the BPM noise was evaluated for each BPM and kick individually and applied as the noise for each turn.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/tbtBpmNoise_iqrVstd.pdf}
    \caption{BPM noise over last 2000 turns, standard deviation and interquartile range markers included}
    \label{fig:bpmErrIQR}
\end{figure}

Figure \ref{fig:bpmErrSet} shows the resulting error evaluation for a full collection. This is a smaller example collection from the rest considered in this section to be a little easier to read. The vertical and horizontal BPM signals are seperated with the red line. We can see that the oddball BPM A1C has a supressed uncertainty from its improper calibration. The other standout bpm is the unusally high noise on the horizontal signals on E2L, an issue with the hardware. We can see a steady growth in the uncertianty over the collection as the circulating current decreases. The individual fits capture the relative uncertainty for their given kick.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/globalBpmIqr_nocal.png}
    \caption{BPM noise over last 2000 turns, IQR evaluation for a full collection}
    \label{fig:bpmErrSet}
\end{figure}

The reduced chi square of each turn was used to evaluate the goodness of fit to the linear model. In the ideal case a reduced chi square value of one indicates a good fit. In practice, estimation of uncertianty and data preprocesing can impact this value, and we are mostly interested in a reasonably contained rang of reduced chi-square values. Initially, the range of the goodness of fit was very large, with large outliers above and below the central value near one. Excluding turns with large BPM noise significantly improved this metric, and let us consider the impact of other data preprocessing steps on the goodness of fit.

First we consider the linear BPM calibration factors from the LOCO procedure. The real BPMs are not perfectly made or aligned to the principle modes of the beam dynamics. To first order these calibrations are included in the LOCO fits. The resulting parameterization with individual bpm constants is given in eq. \ref{eq:bpmCal}.

\begin{equation}
	x_{meas} = K K_{x} \left( x \cos(ang + ang_{x}) + y \sin(ang + ang_{x})\right)
	\label{eq:bpmCal}
\end{equation}

In Figure \ref{fig:rawVcal} we compare the reduced chi square of the fits to the data before and after the linear calibration. The turns are all from the same large dataset for a fixed lattice configuration with many amplitudes and reinjections. The colored region shows the full extent of the reduced chi square values, and the solid line is an average to give a sense of the distribution. These values are plotted against turn number, in general we can see a trend towards lower reduced chi square values as the signal to noise ratio goes down with decoherence. In these plots a good result is a narrow band, and a lower relative reduced chi squared value indicates better match to the model. We see the distribution get much narrower, and the central values move closer to our nominal value of one.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_rawVcal.pdf}
    \caption{Goodness of Fit}
    \label{fig:rawVcal}
\end{figure}

Individual BPMs can be dropped from the fitting algorigthm in the case of a acquisition error or saturation in the BPM. We know that the A1C BPM has a different geometry and incorrectly applied scaling map, so we investigate the impact on goodness of fit by uniformly dropping it in Figure \ref{fig:rawVA1C}. We see a slight reduction in the size of the band as compared to just applying the calibration. As a result, this BPM was excluded from any momentum reconstruction calculations.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_rawVdropA1CandCalibrate.pdf}
    \caption{Goodness of fit}
    \label{fig:rawVA1C}
\end{figure}

To reduce the uncorrelated noise a principle component analysis was applied to all of the BPMs. The PCA was applied to all BPMs to account for possible coupling. Based on the singular values, the first 8 components of the PCA were used. Figure \ref{calVpca} shows the impact on the goodness of fit between the calibration and dropping A1C and these two steps plus the PCA cleaning step. We see a reduction in the band and a correllated drop in the average reduced chi square away from one. This is an expectd side effect, since we are now over estimating the uncertianty from before the PCA cleaning. The uncertianty is not re-estimated because the interpretation of the tails after PCA is inconsistent, and we prefer to evaluate the PCA on as short of a section of the kick as possible.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_calAndDropVpcaClean.pdf}
    \caption{Goodness of fit}
    \label{fig:calVpca}
\end{figure}

While BPM A1C was consistently excluded, the other BPMs were evaluated and found to be reliable. Figure \ref{fig:prepVB2L} shows the comparison after all of our preprocessing steps with and without BPM B2L as an example. We see no significant deviation in the goodness of fit, and retain all of the rest of the BPMs unless there is some readily identifiable acquisition error with the particular kick sample.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_fullPrepVdropB2L.pdf}
    \caption{Goodness of fit}
    \label{fig:prepVB2L}
\end{figure}

After evaluating and settling on our preprocessing steps we can evaluate the distribution of our reduced chi square values over the course of the collection. Figure \ref{fig:redChiDists} shows this distribution for the first 25 and last 25 turns to account for the decoherence related shift. We see the characteristic reduced chi distribution is preserved. The grey histogram corresponds to every fitted turn, the colored curves indicate increasingly aggresive cuts. The first cut excludes bpms with saturation and errors, and the further cuts are on tbt noise. The reduced chi distribution is preserved and the tails smooth out with the calibration cuts. The green trace corresponds to the sets analyzed in the preprocessing comparisons above.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/10_19_t238_redChiSquare_dists.pdf}
    \caption{Reduced chi square distributions for fully processed data sets, histograms for first 25 turns and last 25 turns to account for general reduction due to decoherence}
    \label{fig:redChiDists}
\end{figure}

To illustrate the result with data, Figure \ref{fig:fitThread} shows the result of a fit for a single turn. The position and momentum are fit from the blue measured points. The fitted position is given by the green diamond, and the effective propogated position from that virtual bpm is illustrated with the green trace.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/fitExampleBPM.pdf}
    \caption{Reconstructed position threaded through the rest of the machine}
    \label{fig:fitThread}
\end{figure}

\section{Kick Amplitude Calibration} \label{sec:kickAmpCal}
The position reconstruction is also valuable for calibrating the amplitude from the kicker. When evaluating the amplitude dependent detuning, we need a consistent way to define the amplitude for different configurations. The position reconstruction with the nonlinear insert is difficult to interpret and depends on the insert setting. We prefer instead to evaluate the effective linear emittance imparted from a kick. To calculate this, we reconstruct the position and momentum for the first turn in the bare lattice and look at the correlation with the kicker setting. Figure \ref{fig:kicCalLilacChrom} shows the reconstructed position and momentum for a few bare lattices with different sextupole configurations. The kicker response is reasonably linear, but we see a difference in calibration between bare lattices. As covered in \ref{sec:sextErr} we know some sextupoles have error terms with feed down effects on the linear lattice. As a result only the lattice with a current LOCO optimization is reliable, for the collections we are interseted in, this is the "lilac" configuration which is what is considered moving forward.


\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{./chapter_3_figures/sextKickCalComp.png}
    \caption{Reconstructed vertical position for lilac sextupole configuration lattices and those with only chromatic compensation}
    \label{fig:kickCalLilacChrom}
\end{figure}

Considering with a large collection of mixed kicks for this bare lattice configuraiton, a few models were considered, but a coupled linear model with a fixed zero intercept performed the best according to the goodness of fit metric. Figure \ref{fig:kickCalFit} shows the reconstructed position and momentum at the virtual BPM and the lines corresponding to no perpendicular kicker setting. The calibration parameters are given in \ref{tab:kickCal}. The coupling can be interpreted as a slight roll misalignment of the kicker about the longitudinal axis.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/kickCalLilac.png}
    \caption{Reconstructed First Turn position and momentum with fitted kicker setting calibrations}
    \label{fig:kickCalFit}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{lcc}
    \toprule
    \textbf{Reconstructed Coordinate} & \textbf{Horizontal Kicker} & \textbf{Vertical Kicker}\\
    \midrule
    $x$ [m] & -\num{6.8e-4} $\pm$ \num{1.5e-6} & -\num{2.5e-4} $\pm$ \num{3.3e-6}\\
    $p_x$ [1] & \num{1.1e-4} $\pm$ \num{4.9e-6} & -\num{3.3e-3} $\pm$ \num{1.6e-5}\\
    $y$ [m] & \num{1.9e-3} $\pm$ \num{6.8e-6} & \num{1.3e-4} $\pm$ \num{1.5e-5}\\
    $p_y$ [1] & \num{5.2e-5} $\pm$ \num{4.8e-6} & -\num{3.9e-3} $\pm$ \num{1.6e-5}\\
    \bottomrule
    \end{tabular}
    \caption{Kicker Calibration scaling for "Lilac" bare lattice}
    \label{tab:kickCal}
\end{table}

This amplitude calibration could be used directly or to generate the initial values for a short position reconstruction between the kicker and the nonlinear insert.

\section{Dynamic Aperture Evaluation} \label{sec:daEval}
The dynamic aperture (DA), or amplitude limit on stable motion, is a crucial metric of the real nonlinear system with full perturbations. The dynamic aperture is evaluated for simulated beams as the limit of asymptotically stable trajectories. For experimental measurements, the interpretation becomes more difficult. DA scans were performed by measuring the losses of kicked circulating beam. A consistent qualitative metric was applied, the loss limit was defined as a percent loss greater than 25\% or two subsequent kicks with percent losses greater than 10\%.

For a particular DA scan, a bunch was injected and scraped to a standard initial current in the BPM sensitivity range. The beam was iteratively kicked along fixed ratio "spokes" as current was logged. Once the current reached a minimum threshold, another bunch was injected and the scan of another spoke began.  Figure \ref{fig:spokes} illustrates the resulting geometry of the kick amplitudes.

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{placeholder.pdf}
	\caption{Dynamic Aperture Scan configuration}
	\label{fig:spokes}
\end{figure}

Both the BPMs and DCCT were used to monitor beam current after a kick. The sum of the individual BPM button responses can be used as a fast indicator of losses. The BPM TBT output contains 20 turns of information before the kicker fires. For loss comparisons, the mean of the BPM signal for the first and last 20 turns was compared. The sample range of the BPMs was around 7000 turns which corresponds to a timescale of just under a millisecond. The DCCT signal was sampled before and after the kick on a timescale of a second. Loss timescales differed, some losses on kick were visible in the first few turns of the sum signal, and some losses were not visible in the sum signal but were visible in the DCCT. 

The noise in the DCCT signal was evaluated as the RMS noise with no circulating beam. The sum signal noise was evaluated as the RMS of the availible sample range.

To ensure that losses occurred in the time span between the DCCT samples, and were not dominated by the natural circulating beam lifetime, the difference between the second sample and the first sample of the next kick were calculated and verified to be at the level of noise in the DCCT signal. Figure \ref{fig:dcctKickLife}. DCCT noise was evaluated as the standard deviation without any circulating beam at \num{6.7e-3} [mA].


\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{placeholder.pdf}
	\caption{Change in DCCT current between DA scan kicks}
	\label{fig:dcctKickLife}
\end{figure}

Figure \ref{fig:daLimit} shows the DCCT and BPM sum signal for increasing kicks along a particular spoke. The red line indicates the determined DA limit for the particular spoke.

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{placeholder.pdf}
	\caption{Percent Losses after individual kicks in a DA scan}
	\label{fig:daLimit}
\end{figure}

\section{Synchrotron Profiles} \label{sec:synchProfiles}
In addition to their very useful capacity as live beam monitoring instruments, the synchrotron radiation cameras were used to evaluate the stability of the beam at the integer resonance condition. These measurments were taken with very low circulating beam currents, the cameras are sensitive down to single orbiting electrons, but the exposure has to be periodically adjusted to maintain sensitivity. The transverse profile and the intensity were the points of reference. The images were preprocessed with a media filter to remove potential hot pixels, and a background subtraction was applied. Figure \ref{fig:synchBackground} shows an example camera profile with the marginal sums and a line indicating where the boundary of the background sample.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/t528_M1L_optimized_profile.png}
	\caption{Example Synchtrotron Radiation profile in M1L beyond integer resonance, axes ticks are simply for scale, not absolute position}
	\label{fig:synchBackground}
\end{figure}

To evaluate the lifetime from camera images, the relative intensity (simply the sum of the full image) and timestamps of the image could be fit with an exponential decay, eq. \ref{eq:expLife}. The uncertianty of the lifetime was determined from the uncertainty in the fit.

\begin{equation}
	I(t) = I_o e^{-\frac{t}{\tau}}
	\label{eq:expLife}
\end{equation}
