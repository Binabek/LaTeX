\chapter{Experimental Analysis Methods} \label{chap:analysis}

\section{Tune Measurements} \label{sec:tune}
Tune measurements provide long term coherent information on the dynamics and the strong dependence on amplitude is the chief experimental indicator of nonlinearities in the focusing. Decoherence limits the available turns for measurements, with higher amplitude dependence increasing the rate \cite{jicongshiDecoherenceRecoherenceBeam1993}. The tune was previously defined only for the linear system in the context of phase advance. The definition of the tune is more nebulous then for a strongly nonlinear system, as the motion is necessarily anharmonic. For nonlinear dynamical systems, the Poincar\'{e} rotation number is a related quantity \cite{nagaitsevBetatronFrequencyPoincare2020}, but difficult to relate to measurable quantities. For the experimental measurements, we interpret the dominant frequency of the transverse oscillation spectrum as the tune. 

Different tune measurement algorithms were considered for the particular limitations of the available data. The simplest approach is taking the Fourier transform of turn by turn (TBT) BPM data and picking the peak frequency. As we have discrete sampling of the motion, a discrete Fourier transform is a simple first approach. Practically, the fast Fourier transform (FFT) is used as the default discrete transform. There are a number of methods to improve the resolution of the frequency measurements. In principle a windowing function can be applied to improve resolution of the peak frequency at the cost of suppressing sidebands. However, for the IOTA data, there are two important considerations. A window suppresses the amplitude of a fraction of the sample window. In the case of the short coherent measurements, the reduction in available signal was more detrimental than the advantages of the window. And for low signal to noise ratios the benefits of a window disappear. For example, the common Hann window does not provide any benefits for signal to noise ratios less than \num{1e3} \cite{bartoliniAlgorithmsPreciseDetermination1996}, well above those seen in IOTA. To bypass some of the limitations on the discrete sample resolution of the FFT, Jacobsen interpolation \cite{jacobsenLocalInterpolationDFT} applies a quadratic interpolation to the FFT peak and its nearest neighbors for finer peak resolution. The implementation used is based on that from the PyLHC \cite{cernomcteamPyLHC} analysis library. The other approach considered is the Numerical Analysis of Fundamental Frequencies (NAFF) proposed by Laskar for the evaluation of long term stability of planetary systems \cite{laskarMeasureChaosNumerical1992}. NAFF starts with a guess from the FFT spectrum, and seeks to iteratively optimize the magnitude of a single Fourier transform as in equation \ref{eq:naff}. In principle this can be used to extract successive harmonics of the motion, but we are interested only in the dominant frequency, so typically only one term is considered. The implementation of NAFF used in this analysis is PyNAFF \cite{zisopoulosPZisoPyNAFF2023}, this uses Hardy's method (Eq. \ref{eq:hardy} \cite[p.151]{whittakerCalculusObservations1924}) for the numerical integration as opposed to a simple Riemann sum. In addition to the offline methods, live tune measurements on circulating beam used a least squares approach, where an assumed functional form with free parameters for tune, phase, coupling, and decoherence times, is fit to the data.

\begin{equation}
	\Psi(T) = \frac{1}{2T}\int_{-T}^{T}f(t)e^{-i\omega t}dt
	\label{eq:naff}
\end{equation}

\begin{equation}
	\int_{x_{n}}^{x_{n+6}}f(x)dx \approx \frac{\Delta x}{100}\left(28(f(x_n) + f(x_{n+6})) + 162(f(x_{n+1}) + f(x_{n+5})) + 220 f(x_{n+3}) \right)
	\label{eq:hardy}
\end{equation}

To evaluate the methods, a comparison was made with both a synthetic signal and the simulated bunch centroid signal from an Impact-X simulation. Figure \ref{fig:synKicks} shows the evaluation signals, the amplitude does not impact the tune evaluation. The synthetic signal consisted of a convolution of a single harmonic base signal, a logistic function for decoherence and a Gaussian noise distribution with a RMS of ten percent of the signal amplitude. For these comparative studies, only a single underlying tune was evaluated, dictated by the measured tune from the simulated signal.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/syntheticAndSimulationKicks.pdf}
	\caption{Evaluation signals, fully synthetic and simulated}
	\label{fig:synKicks}
\end{figure}

The first evaluation was on the convergence of the various methods. Figure \ref{fig:baseConv} shows the convergence of tune measurements for the various considered algorithms with increasing length of the sample window. The limitations of the FFT resolution from the available signal are clear, but they inform the initial values for the interpolation and the NAFF. The vertical simulation signals are considered here as they exhibit faster decoherence. The relatively long coherence time of the horizontal signal means that convergence rate is less important, and we are interested in best performance for very fast decoherence.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/basicConvergence.pdf}
	\caption{Convergence of tune measurements with length of signal window}
	\label{fig:baseConv}
\end{figure}

The available resolution of the FFT can be improved by padding the input signal with zero values. This is the same effect as increasing the length of the signal and applying a rectangular window the length of the original signal. Figure \ref{fig:padConv} shows the convergence of the faster methods with and without padding. Here all signals were padded to an equal signal length of 256 turns. We see that the convergence of the padded FFT is improved, but the windowing effect introduces a systematic, limited offset of the tune determined by the length of the padding. The Jacobsen interpolation with a padded signal also suffers a similar effect, converging on a systematically offset tune.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/paddedConvergence.pdf}
	\caption{Convergence of tune measurements with zero padding}
	\label{fig:padConv}
\end{figure}

We then have three approaches which reliably converge before the 100 turn limit of our sample plots, Jacobsen interpolation without padding, and NAFF with and without padding. In evaluating the quality of the convergence, the noise seed on the simulated signal was found to have a significant effect on these methods. The convergence of the tune measurement was evaluated for the same underlying synthetic signal and decoherence as before but with one thousand different noise seeds for the random noise. The synthetic signal was used as there is a guarantee of a single underlying frequency unlike the simulation signal. The ensemble properties of the convergence are plotted in Figure \ref{fig:noiseConv}. The left plot shows the mean of the absolute difference of the measured tune from the nominal, $|Q_{meas} - Q_{nominal}|$ and the right plot is the standard deviation of the measured tunes for each window length. We see that the average convergence is about the same, with a slight preference for Jacobsen interpolation. The padded NAFF measurements have slightly lower variation.


\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/noiseSeedConvergence.pdf}
	\caption{Convergence of tune measurements with zero padding}
	\label{fig:noiseConv}
\end{figure}

There is an additional consideration, we can evaluate the accuracy of the measurements while adjusting the initial phase. For kicked beam collection, the kicker fires at the same point in the beam every time, so we can evaluate changes in phase by changing the initial turn. In the measured TBT data, there is a periodic variation of the measured tune for a shift in initial turn. This necessarily means sampling a lower amplitude region of the signal as you go along the decoherence. With the padded signal we can also do a similar transformation without losing information. By ``rolling" the padding at the end of the signal to the front maintaining the same overall signal length, different phases are sampled, only limited by the resolution of the binning. Figure \ref{fig:baseRoll} shows the change in the tune measurements for varying the initial turn of a sixty turn sample window and ``rolling" the padded signal. Note that the first value of the NAFF padded and the NAFF rolled circled in black are exactly the same as they are evaluating the same signal. This comparison is not apples-to-apples but it does imply a benefit of the NAFF ``rolled" evaluation. For a given signal length the uncertainty due to the initial phase is regular and can be evaluated without sampling different, presumably lower amplitude areas of the original signal.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{./chapter_3_figures/slideTuneComparison.pdf}
	\caption{Variation of tune measurements with initial phase}
	\label{fig:baseRoll}
\end{figure}

The different tune measurement algorithms have different characteristic statistical uncertainties that scale with the available sample window. Without interpolation, the uncertainty in the FFT lines goes as $\frac{1}{N}$ where N is the sample length, in our case available turns. Both the un-windowed NAFF and interpolation approaches have analytic uncertainties that go as $\frac{1}{N^2}$ \cite{zisopoulosRefinedBetatronTune2019,bartoliniTuneEvaluationSimulations1996}. The magnitude of the variation due to initial phase was added to the uncertainty of the tune measurements. We then have the following steps for a single signal tune measurement: \begin{enumerate}
	\item{Zero pad signal to predetermined length}
	\item{Evaluate the tune with NAFF}
	\item{``Roll" the signal to shift initial phase}
	\item{Evaluate rolled signal with NAFF}
	\item{Repeat roll and evaluation a predetermined number of times, and estimate initial phase uncertainty from variance in rolled tune measurements}
\end{enumerate}

This algorithm is applied to the real TBT bpm sample (Figure. \ref{fig:realEvalSig}) in  Figure \ref{fig:measConvRoll}.

\begin{figure}
	\centering \includegraphics[width=1\linewidth]{./chapter_3_figures/realTuneEvalSignal.pdf}
	\caption{Example kick for tune evaluation, BPM B1R signal}
	\label{fig:realEvalSig}
\end{figure}


\begin{figure}
	\centering \includegraphics[width=1\linewidth]{./chapter_3_figures/realTuneConvergence.pdf}
	\caption{Tune measurement convergence for measured TBT data, with estimated uncertainty}
	\label{fig:measConvRoll}
\end{figure}


The above comparisons assume a single signal, but multiple BPM signals are available and we would like to combine them, there were two approaches considered. The first is a BPM stacking approach, where a quasi-periodic signal is constructed \cite{zisopoulosRefinedBetatronTune2019} by stacking sequential BPMs. This approach did not yield good results for the experimental IOTA data.

The other considered approach to investigate multiple BPM response was to select the dominate components of a PCA decomposition of all combined BPM signals. PCA was selected as the scikit-learn implementation of PCA was significantly more performant than the numpy implementation of SVD, with the same resulting singular values. Figure \ref{fig:pcaComps} shows the matrix resulting from the convolution of the BPM-specific terms in the PCA with the singular values of a single kick, the same kick as shown in \ref{fig:realEvalSig}. Each column corresponds to a BPM, with the center line indicating the split between the horizontal and vertical BPM labels. 

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{./chapter_3_figures/t238_singleKickPCA.pdf}
	\caption{PCA decomposition of TBT signals }
	\label{fig:pcaComps}
\end{figure}

The rows indicate different temporal signals. To provide some insight, in the case of transverse simple harmonic motion we would expect four terms, two components for each phase in each plane. For long sample times, PCA may become sensitive to the synchrotron frequency, but this is not the case in IOTA. Each BPM signal is then composed of the relevant fraction of these phase components with scaling proportional to the beta function at that location. Figure \ref{fig:pcaTemps} shows the first four temporal components of the same decomposition. 

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/pcaTemporalModes.pdf}
	\caption{First four PCA temporal modes from decomposition above}
	\label{fig:pcaTemps}
\end{figure}

We can then discriminate on the direction of a tune component by looking at the relative magnitudes of the temporal components in the horizontal and vertical BPMs. A tune measurement technique, NAFF in this case, can then be applied to these individual components. This has the slight drawback of making phase measurements of individual BPMs more difficult, but this is not typically considered for the analysis anyways. The other drawback of this approach is that it requires the same number of turns to be considered for each plane. The nature of the PCA decomposition with all BPM signals means that if there is a strong discrepancy between the decoherence times in different planes (which is not uncommon), necessarily we have to throw away coherent data in one plane or consider a longer range of signal beyond decoherence in the other.

Another effect on tune measurements is resonant capture, briefly discussed in section \ref{sec:bunchSims}, where a small fraction of the beam becomes trapped in a resonant condition and continues to oscillate at the characteristic frequency of the resonance. As the rest of the beam quickly decoheres due to tune spread, this dominates tune measurements with long sample windows. This can be seen in the spectrogram with short vertical decoherence with a long faint line. Figure \ref{fig:resCapReal} shows the profile for a kick demonstrating resonant capture. The vertical decoherence is very fast, about 20 turns. However, a small portion of the beam continues to coherently oscillate as can be seen in the spectrogram in Figure \ref{fig:specResCap}. This spectrogram has a window length of 60 turns. The dominant peak in the first window is with the decohering main tune line, but we see a faint line with one bin lower tune and long coherence right on the third order difference line $Q_x-2Q_y = 0$.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/resonantCaptureSignal.pdf}
	\caption{Example resonant capture kick}
	\label{fig:resCapReal}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/resonantCaptureSpectogramB1R_238_10_19_kick26.png}
	\caption{Resonant capture spectrogram}
	\label{fig:specResCap}
\end{figure}

This resonant capture effect means we prefer to keep the tune measurement windows as short as gives reasonable tune resolution. This effect has been demonstrated in simulation, with kicked bunch measurements, and can be seen in single-electron measurements \cite{romanovalexanderAnalysisEllipticIntegrable2025}.

\section{Nonlinear Insert Calibration} \label{sec:nioCal}
The nonlinear insert had to be calibrated and aligned to best match the nominal potential. This was done with beam based measurements. Recalling from section \ref{sec:nioDesign} that the lowest order component of the nonlinear insert is a quadrupole, and that the proper implementation of the DN NIO system requires consistent longitudinal scaling to properly match the potential, we treat the individual DN magnets as quadrupoles for small amplitudes. LOCO was applied to center the individual elements, the measured closed orbit offsets after centering \textit{assuming quadrupole terms} are presented in \ref{fig:dnOffset}. 

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{./chapter_3_figures/dnOrbitOffsets.pdf}
	\caption{Closed orbit offsets in DN magnet after manual alignment, assuming quadrupole terms}
	\label{fig:dnOffset}
\end{figure}


Each magnet was energized individually and a small amplitude kick was applied to the beam to measure the tune shift. This was done for multiple current setpoints to fit a tune shift vs current.
The individual scaling of the nonlinear t-parameter to current was calibrated for each magnet using the tune shift due to a quadrupole error in the lattice, (eq. \ref{eq:quadErrShift}) set equal to the quadrupole term of the DN potential (eq. \ref{eq:dnQuadTerm}), and solved for t.

\begin{equation}
    	\Delta Q_{x} = \pm \frac{1}{4\pi}\int{\beta_x(s) \frac{\Delta B_2}{B\rho} ds}
    	\label{eq:quadErrShift}
\end{equation}

\begin{equation}
	\Delta B_2 = \frac{-2B\rho \Delta t}{\beta^2(s)}
	\label{eq:dnQuadTerm}
\end{equation}

The resulting data gives a relative current scaling profile for the overall insert Fig. \ref{fig:dnIscaling}. This calibration assumes good accuracy of the beta functions in the nonlinear insert at the time of the calibration.

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{./chapter_3_figures/2023-05-22dnScalings.pdf}
    \caption{Relative DN insert current scaling profile compared to calculated ideal values}
    \label{fig:dnIscaling}
\end{figure}

This approach gives good relative scaling of the magnets, but we want to additionally evaluate the calibration of the insert as a whole. The tune shift assuming only the quadrupole terms of the DN element is given in Eq. (\ref{eq:dnDetune}) \cite{nagaitsevNonlinearOpticsPath2012}.

\begin{equation}
	\begin{split}
	Q_{x} = Q_{o}\sqrt{1+2t} \\
        Q_{y} = Q_{o}\sqrt{1-2t}
	\end{split}
	\label{eq:dnDetune}
\end{equation}

The tune shift of the insert was measured by adjusting the t-parameter of the entire DN insert, according to the previously calibrated current ratios and kicking the beam to small amplitudes to measure the tune. The measured tune shift for increasing excitation of the nonlinear insert is plotted in Figure \ref{fig:dnDetuning}. The impact of the sextupoles used to compensate chromaticity can be seen as the dominant effect on the tune near the third order resonances (red lines on tune diagram).

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/tuneSpaceDnShift.pdf}
    \caption{Measured nonlinear insert tune shift detuning}
    \label{fig:dnDetuning}
\end{figure}

The ratio of the tune shift between the planes is good indicator of proper implementation of the longitudinal scaling of the potential and beta function match in the insert. The absolute t-parameter scaling was calibrated by measuring tune shift vs nominal t-parameter, as presented in Figure \ref{fig:dnTuneVsT}. The gap in the data between t=0.2 t=0.3 was an unfortunate result of the BPM system freezing and failing to update TBT data, and was simply excluded.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/dnDetuningCalFactor.pdf}
    \caption{Tune shift vs t-parameter in both planes, before and after scaling}
    \label{fig:dnTuneVsT}
\end{figure}

The initial data indicated a discrepancy in the tune dependence of the t-parameter. The ideal detuning expression was fit to the data with a t-scaling factor as the only free parameter Eq. (\ref{eq:fitTune}). 

\begin{equation}
    Q = Q_o \sqrt{1\pm 2at}
    \label{eq:fitTune}
\end{equation}

The fit resulted in a calibrated t-parameter scaling of $a \approx 0.935$. The source of this discrepancy is not clear, but may be a result of magnet crosstalk, as the relative calibration was measured with single elements and the magnet spacing is close.

\section{Momentum Reconstruction} \label{sec:momReconst}
For studying the evolution of the phase space, the four dimensional $(x,p_x,y,p_y)$ transverse coordinates of the beam need to be reconstructed. There are a few standard ways to accomplish this. The simplest approach is a pair of BPMs with a $\phi = \pi/2$ phase advance between them. This is a straightforward start, but we have more than two BPMs and would like to combine the signals. A popular approach to this is the N-BPM method \cite{langnerOpticsMeasurementAlgorithms2015}, which can reconstruct the momentum from measured beta functions. The most accurate beta function measurements use the measured linear phase advance between BPMs to adjust the analytical nominal values. In the case of IOTA with the NIO insert, the tune and therefore phase advance is highly nonlinear and not a reliable parameter to combine with the bare lattice. Instead we leverage the linear model of the lattice optimized to using LOCO. The momentum and position at a virtual BPM could then be reconstructing using a least squares approach. 

The BPMs are all located in the linear matching section of the lattice. We can then reconstruct the position and momentum at a virtual BPM turn by turn, using the linear model from LOCO. The main nonlinearity in IOTA stems from the insert, though there is nonlinearity stemming from the sextupoles, fringe fields, and sharp bending dipoles. Using higher order maps including the calibrated sextupole terms was considered, but expanding the method using second order transfer maps yielded poor convergence of the fits. Additionally, such a method would require more accurate understanding of the residual nonlinearities in the matching lattice than we currently have for IOTA. We have an advantage in that the nonlinear effects outside of the insert are perturbative compared to the linear focusing terms, so we only expect them to be significant over many turns. This motivates carefully evaluating the goodness of fit to our linear model later in this section. So then, for the fitting, the matching section was essentially treated in a channel mode from the end of the nonlinear insert to the beginning of it.

To perform the least squares fit the lmfit python package \cite{newvilleLMFITNonLinearLeastSquares2025} was used. The nonlinear least squares efforts are irrelevant for the linear transport model, but the interface is much improved over other pythonic options, e.g. scipy. For our fits the free parameters are the position and momentum at a virtual BPM. Our model is the linear transfer matrices to each BPM from the virtual BPM location. In principle, these could be coupled, but the coupling is deliberately locally corrected with the IOTA skew quad correctors. The resulting transfer matrices have coupling on the order of the machine precision, so we simply exclude these terms to reduce the dimensionality of the fit. Accordingly, we perform a fit for each plane. The data for the fit is the BPM measured position at each BPM in a given turn. To ascribe an uncertainty to our reconstructed coordinates we need an understanding of the uncertainty in our BPM measurements.

The uncertainty of the BPM measurements is evaluated from the variation in the tails long after the signal fully decoheres. Note that the radiation damping time for the beam ~3 orders of magnitude longer than this sample time. The individual particles are still at mostly full amplitude and our beam is ``large". This may impact the centroid measurements if the nonlinear BPM calibration factors are off, as a fraction of the beam near the buttons may be under-sampled or saturate the acquisition electronics. Some preprocessing was applied to the BPM signals to excluded these effects. For NIO lattice configurations, the tail was defined to be 2000 turns from the end, well past the expected coherence limit. Figure \ref{fig:bpmErrCutoff} shows the full sample range of an example kick in IOTA with a line indicating the noise sample threshold.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/exampleKick_pointDN_t238.pdf}
    \caption{Full range IOTA example kick with error estimation cutoff}
    \label{fig:bpmErrCutoff}
\end{figure}

The error in the BPM measurements is then evaluated to be the variance in this remaining signal. Figure \ref{fig:bpmErrIQR} shows the histogram of coordinates in the last thousand turns in Figure \ref{fig:bpmErrCutoff}. The standard deviation and interquartile range are both calculated and compared. The interquartile range is less susceptible to outliers, and can be directly related to the standard deviation if the distribution is Gaussian. A comparison of these metrics for a large sample of real IOTA kicks showed good correspondence, indicating that the bpm noise is well modeled with the normal distribution. For fitting, the BPM noise was evaluated for each BPM and kick individually and applied as the noise for each turn.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/tbtBpmNoise_iqrVstd.pdf}
    \caption{BPM noise over last 2000 turns, standard deviation and interquartile range markers included}
    \label{fig:bpmErrIQR}
\end{figure}

Figure \ref{fig:bpmErrSet} shows the resulting error evaluation for a full collection. This is a smaller example collection from the rest considered in this section to be a little easier to read. The vertical and horizontal BPM signals are separated with the red line. We can see that the oddball BPM A1C has a suppressed uncertainty from its improper calibration. The other standout bpm is the unusually high noise on the horizontal signals on E2L, an issue with the hardware. We can see a steady growth in the uncertainty over the collection as the circulating current decreases. The individual fits capture the relative uncertainty for their given kick.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/globalBpmIqr_nocal.png}
    \caption{BPM noise over last 2000 turns, interquartile range evaluation for a full collection}
    \label{fig:bpmErrSet}
\end{figure}

The reduced chi square of each turn was used to evaluate the goodness of fit to the linear model. In the ideal case a reduced chi square value of one indicates a good fit. In practice, estimation of uncertainty and data preprocessing can impact this value, and we are mostly interested in a reasonably contained rang of reduced chi-square values. Initially, the range of the goodness of fit was very large, with large outliers above and below the central value near one. Excluding turns with large BPM noise significantly improved this metric, and let us consider the impact of other data preprocessing steps on the goodness of fit.

First we consider the linear BPM calibration factors from the LOCO procedure. The real BPMs are not perfectly made or aligned to the principle modes of the beam dynamics. To first order these calibrations are included in the LOCO fits. The resulting parameterization with individual bpm constants is given in eq. \ref{eq:bpmCal}.

\begin{equation}
	x_{meas} = K K_{x} \left( x \cos(ang + ang_{x}) + y \sin(ang + ang_{x})\right)
	\label{eq:bpmCal}
\end{equation}

In Figure \ref{fig:rawVcal} we compare the reduced chi square of the fits to the data before and after the linear calibration. The turns are all from the same large data set for a fixed lattice configuration with many amplitudes and re-injections. The colored region shows the full extent of the reduced chi square values, and the solid line is an average to give a sense of the distribution. These values are plotted against turn number, in general we can see a trend towards lower reduced chi square values as the signal to noise ratio goes down with decoherence. In these plots a good result is a narrow band, and a lower relative reduced chi squared value indicates better match to the model. We see the distribution get much narrower, and the central values move closer to our nominal value of one.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_rawVcal.pdf}
    \caption{Goodness of Fit}
    \label{fig:rawVcal}
\end{figure}

Individual BPMs can be dropped from the fitting algorithm in the case of a acquisition error or saturation in the BPM. We know that the A1C BPM has a different geometry and incorrectly applied scaling map, so we investigate the impact on goodness of fit by uniformly dropping it in Figure \ref{fig:rawVA1C}. We see a slight reduction in the size of the band as compared to just applying the calibration. As a result, this BPM was excluded from any momentum reconstruction calculations.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_rawVdropA1CandCalibrate.pdf}
    \caption{Goodness of fit}
    \label{fig:rawVA1C}
\end{figure}

To reduce the uncorrelated noise a principle component analysis was applied to all of the BPMs. The PCA was applied to all BPMs to account for possible coupling. Based on the singular values, the first 8 components of the PCA were used. Figure \ref{fig:calVpca} shows the impact on the goodness of fit between the calibration and dropping A1C and these two steps plus the PCA cleaning step. We see a reduction in the band and a correlated drop in the average reduced chi square away from one. This is an expected side effect, since we are now over estimating the uncertainty from before the PCA cleaning. The uncertainty is not re-estimated because the interpretation of the tails after PCA is inconsistent, and we prefer to evaluate the PCA on as short of a section of the kick as possible.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_calAndDropVpcaClean.pdf}
    \caption{Goodness of fit}
    \label{fig:calVpca}
\end{figure}

While BPM A1C was consistently excluded, the other BPMs were evaluated and found to be reliable. Figure \ref{fig:prepVB2L} shows the comparison after all of our preprocessing steps with and without BPM B2L as an example. We see no significant deviation in the goodness of fit, and retain all of the rest of the BPMs unless there is some readily identifiable acquisition error with the particular kick sample.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{./chapter_3_figures/redChiSquare_10_19_t238_fullPrepVdropB2L.pdf}
    \caption{Goodness of fit}
    \label{fig:prepVB2L}
\end{figure}

After evaluating and settling on our preprocessing steps we can evaluate the distribution of our reduced chi square values over the course of the collection. Figure \ref{fig:redChiDists} shows this distribution for the first 25 and last 25 turns to account for the decoherence related shift. We see the characteristic reduced chi distribution is preserved. The gray histogram corresponds to every fitted turn, the colored curves indicate increasingly aggressive cuts. The first cut excludes BPMs with saturation and errors, and the further cuts are on TBT noise. The reduced chi distribution is preserved and the tails smooth out with the calibration cuts. The green trace corresponds to the sets analyzed in the preprocessing comparisons above.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/10_19_t238_redChiSquare_dists.pdf}
    \caption{Reduced chi square distributions for fully processed data sets, histograms for first 25 turns and last 25 turns to account for general reduction due to decoherence}
    \label{fig:redChiDists}
\end{figure}

To illustrate the result with data, Figure \ref{fig:fitThread} shows the result of a fit for a single turn. The position and momentum are fit from the blue measured points. The fitted position is given by the green diamond, and the effective propagated position from that virtual bpm is illustrated with the green trace.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/fitExampleBPM.pdf}
    \caption{Reconstructed position threaded through the rest of the machine}
    \label{fig:fitThread}
\end{figure}

To summarize, the full phase space variables were reconstructed from TBT data at a virtual BPM using least squares fitting to the linear lattice model. The model consisted of the linear dominated matching section of the lattice excluding the NIO insert to exclude the nonlinear dominated region. To ensure good quality of the fits, the goodness of fit for various preprocessing steps was evaluated. This required a good model of the BPM uncertainty, which was extracted on a kick-by-kick basis. Applying BPM calibrations, dropping a problematic BPM, and applying PCA to the TBT data showed the best results for limiting the variance in the goodness of fit and demonstrated the expected chi-square distribution. These efforts give us good confidence in the quality of the LOCO optimization of the linear lattice and uncertainties in the TBT extracted quantities from the data. 

\section{Kick Amplitude Calibration} \label{sec:kickAmpCal}
The position reconstruction is also valuable for calibrating the amplitude from the kicker. When evaluating the amplitude dependent detuning, we need a consistent way to define the amplitude for different configurations. The position reconstruction with the nonlinear insert is difficult to interpret and depends on the insert setting. We prefer instead to evaluate the effective linear emittance imparted from a kick. To calculate this, we reconstruct the position and momentum for the first turn in the bare lattice and look at the correlation with the kicker setting. Figure \ref{fig:kickCalLilacChrom} shows the reconstructed position and momentum for a few bare lattices with different sextupole configurations. The kicker response is reasonably linear, but we see a difference in calibration between bare lattices. From operational experience, we know some sextupoles have error terms with feed down effects on the linear lattice \ref{apx:sextErr}. As a result only the lattice with a current LOCO optimization is reliable, for the collections we are interested in, this is the ``lilac" configuration described in section \ref{sec:kickBeam}.


\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{./chapter_3_figures/sextKickCalComp.png}
    \caption{Reconstructed vertical position for ``lilac" sextupole configuration lattices and those with only chromatic compensation}
    \label{fig:kickCalLilacChrom}
\end{figure}

Considering with a large collection of mixed kicks for this bare lattice configuration, a few models were considered, but a coupled linear model with a fixed zero intercept performed the best according to the goodness of fit metric. Figure \ref{fig:kickCalFit} shows the reconstructed position and momentum at the virtual BPM and the lines corresponding to no perpendicular kicker setting. The calibration parameters from the arbitrary unit, control system kicker settings to the reconstructed coordinate are given in \ref{tab:kickCal}. The coupling can be interpreted as a slight roll misalignment of the kicker about the longitudinal axis.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{./chapter_3_figures/kickCalLilac.png}
    \caption{Reconstructed First Turn position and momentum with fitted kicker setting calibrations}
    \label{fig:kickCalFit}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{lcc}
    \toprule
    \textbf{Reconstructed Coordinate} & \textbf{Horizontal Kicker} & \textbf{Vertical Kicker}\\
    \midrule
    $x$ [m] & -\num{6.8e-4} $\pm$ \num{1.5e-6} & -\num{2.5e-4} $\pm$ \num{3.3e-6}\\
    $p_x$ [1] & \num{1.1e-4} $\pm$ \num{4.9e-6} & -\num{3.3e-3} $\pm$ \num{1.6e-5}\\
    $y$ [m] & \num{1.9e-3} $\pm$ \num{6.8e-6} & \num{1.3e-4} $\pm$ \num{1.5e-5}\\
    $p_y$ [1] & \num{5.2e-5} $\pm$ \num{4.8e-6} & -\num{3.9e-3} $\pm$ \num{1.6e-5}\\
    \bottomrule
    \end{tabular}
    \caption{Kicker Calibration scaling for ``lilac" sextupole configuration in bare lattice}
    \label{tab:kickCal}
\end{table}

This amplitude calibration could be used directly or to generate the initial values for a short position reconstruction between the kicker and the nonlinear insert.

\section{Dynamic Aperture Evaluation} \label{sec:daEval}
The dynamic aperture (DA), or amplitude limit on stable motion, is a crucial metric of the real nonlinear system with full perturbations. The dynamic aperture is evaluated for simulated beams as the limit of asymptotically stable trajectories. For experimental measurements, the interpretation becomes more difficult. The DA measurements settled on were performed by measuring the losses of kicked circulating beam at increasing amplitudes. Two methods were used to evaluate the dynamic aperture, a fast coarse approach implemented online for optimization purposes, and a more granular method employing postprocessing. 

The coarse approach consisted of fitting a logistic function to the characteristic current curve of repeated losses versus kick amplitude. The offset of the logistic function could be used as a relative metric for the location of the aperture. Figure \ref{fig:acnetDA} shows the raw output in the Fermilab ACNET control system that was used for the fitting. The green trace is the DCCT current, the red trace is a rolling average of the same measurement, and the yellow trace is the calibrated current as measured by the PMT. The spikes in the PMT signal correspond to kicks, as the center of the PMT window is discolored, so when the beam size increases after a kick the spot size increases beyond this artificially suppressed region on the diagnostic. This ended up being an additional useful indicator of successful kicks in the machine. This method relies on many assumptions, the losses between the kicks are consistent, the kick timing is regular, and the initial current is consistent. However, it was relatively fast, and resulted in a simple single figure of merit, both very useful features for input into an optimizer

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{./chapter_3_figures/2023-10-01acnetSigmoidScan.png}
	\caption{ACNET control system readout of currents during a logistic fit DA scan}
	\label{fig:acnetDA}
\end{figure}

For the more granular, postprocessed DA scans, a bunch was injected and scraped to a standard initial current in the BPM sensitivity range. The beam was iteratively kicked along fixed ratio ``spokes" as current was logged. Once the current reached a minimum threshold, another bunch was injected and the scan of another spoke began.  Figure \ref{fig:spokes} illustrates the resulting geometry of the kick amplitudes.

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{./chapter_3_figures/spokesExample.pdf}
	\caption{Dynamic Aperture Scan configuration}
	\label{fig:spokes}
\end{figure}

Both the BPMs and DCCT were used to monitor beam current after a kick. The sum of the individual BPM button responses can be used as a TBT indicator of losses. The BPM TBT output contains 20 turns of information before the kicker fires, which can be used as a baseline. For loss comparisons, the mean of the BPM signal for the first and last 20 turns was compared. The sample range of the BPMs was around 7000 turns which corresponds to a timescale of just under a millisecond. The sum signal from all of the BPMs was combined TBT to form a global sum signal. The sum signal noise was evaluated as the standard deviation of these sample ranges. 

The DCCT signal was sampled before and after the kick on a timescale of a second. Loss timescales differed, some losses on kick were visible in the first few turns of the sum signal, and some losses were too slow to be in the sum signal but were visible in the DCCT. 

To ensure that losses occurred in the time span between the DCCT samples, and were not dominated by the natural circulating beam lifetime, the difference between the second sample and the first sample of the next kick were calculated and verified to be at the level of noise in the DCCT signal. Figure \ref{fig:dcctKickLife}, shows the difference in current after a DA kick and the initial value before the next kick on the order of a few seconds. DCCT noise was evaluated as the standard deviation without any circulating beam at \num{6.7e-3} [mA].

\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{./chapter_3_figures/dcctInterKickLoss.pdf}
	\caption{Change in DCCT current between DA scan kicks}
	\label{fig:dcctKickLife}
\end{figure}

Figure \ref{fig:daLimit} shows the DCCT and BPM sum signal for increasing kicks along a particular spoke. A consistent qualitative metric was applied, the loss limit was defined as a percent loss greater than 25\% or two subsequent kicks with percent losses greater than 10\%. The red line indicates the determined DA limit for the particular spoke.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/percentLossErrorbars.pdf}
	\caption{Percent Losses after individual kicks in a DA scan}
	\label{fig:daLimit}
\end{figure}

\section{Synchrotron Radiation Profiles} \label{sec:synchProfiles}
In addition to their very useful capacity as live beam monitoring instruments, the synchrotron radiation cameras were used to evaluate the stability of the beam at the integer resonance condition. These measurements were taken with very low circulating beam currents, the cameras are sensitive down to single orbiting electrons, but the exposure has to be periodically adjusted to maintain sensitivity. The transverse profile and the intensity were the points of reference. The images were preprocessed with a media filter to remove potential hot pixels, and a background subtraction was applied. Figure \ref{fig:synchBackground} shows an example camera profile with the marginal sums and a line indicating where the boundary of the background sample.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/t528_M1L_optimized_profile.png}
	\caption{Example Synchrotron Radiation profile in M1L beyond integer resonance, axes ticks are simply for scale, not absolute position}
	\label{fig:synchBackground}
\end{figure}

To evaluate the lifetime from camera images, the relative intensity (simply the sum of the full image) and time stamps of the image could be fit with an exponential decay, eq. \ref{eq:expLife}. The uncertainty of the lifetime was determined from the uncertainty in the fit. Experimental results for lifetime measurments are described in section \ref{sec:intCross}.

\begin{equation}
	I(t) = I_o e^{-\frac{t}{\tau}}
	\label{eq:expLife}
\end{equation}

The synchrotron radiation profiles were also used to measure the equilibrium emittance of the circulating beam for the IOTA bare lattice. Figure \ref{fig:iotaEmitVI} shows the emittance dependence as fitted to the camera profiles. The emittance analysis presented was performed by A. Romanov. We see there is some dependence on the circulating current due to intra-beam effects. The lattice in question is the IOTA bare lattice with a small perturbation to split the tunes off of the coupling resonance. The majority of the measurements are taken off of this coupling line, and the beam is much flatter off the coupling from the disparate synchrotron damping in the different planes. As the t-insert is ramped the emittances are of course not strictly conserved, but are nearly transformed to the first order, and is reasonably comparable for small t-parameters. Generally, for most evaluations a central emittance quantity of $\epsilon_x = \num{2.2e-7}$ [m-rad] and $\epsilon_y = \num{3.2e-9}$ [m-rad] is used, as this represents a pretty typical operating current for a particular injection. Recall we are sensitive between 0.5 [mA] and 0.1 [mA] for BPM data.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{./chapter_3_figures/measuredEmittances.png}
	\caption{Measured emittance versus circulating current in split tune bare IOTA lattice}
	\label{fig:iotaEmitVI}
\end{figure}
